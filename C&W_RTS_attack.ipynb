{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDkLejKBGmSt"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.nn.init import normal_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288QVE_VHHLL"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.set_device(0)\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUzuurE3HZh6"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFT1q_U-HvaK"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169_(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhEEMRGoHxDK"
      },
      "outputs": [],
      "source": [
        "class ResNetEncoder(torchvision.models.ResNet):\n",
        "\n",
        "    def forward(self, x):\n",
        "        s0 = x\n",
        "        x = self.conv1(s0)\n",
        "        x = self.bn1(x)\n",
        "        s1 = self.relu(x)\n",
        "        x = self.maxpool(s1)\n",
        "\n",
        "        s2 = self.layer1(x)\n",
        "        s3 = self.layer2(s2)\n",
        "        s4 = self.layer3(s3)\n",
        "\n",
        "        s5 = self.layer4(s4)\n",
        "\n",
        "        x = self.avgpool(s5)\n",
        "        sX = x.view(x.size(0), -1)\n",
        "        sC = self.fc(sX)\n",
        "\n",
        "        return s0, s1, s2, s3, s4, s5, sX, sC\n",
        "\n",
        "\n",
        "def resnet50encoder(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth'))\n",
        "    return model\n",
        "\n",
        "\n",
        "class Bottleneck_(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, bottleneck_ratio=4,\n",
        "                 activation_fn=lambda: torch.nn.ReLU(inplace=False)):\n",
        "        super(Bottleneck_, self).__init__()\n",
        "        bottleneck_channels = out_channels // bottleneck_ratio\n",
        "        self.conv1 = nn.Conv2d(in_channels, bottleneck_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
        "        self.conv2 = nn.Conv2d(bottleneck_channels, bottleneck_channels, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
        "        self.conv3 = nn.Conv2d(bottleneck_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.activation_fn = activation_fn()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.residual_transformer = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=True)\n",
        "        else:\n",
        "            self.residual_transformer = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.residual_transformer is not None:\n",
        "            residual = self.residual_transformer(residual)\n",
        "        out += residual\n",
        "\n",
        "        out = self.activation_fn(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def simple_cnn_block(in_channels, out_channels,\n",
        "                     kernel_size=3, layers=1, stride=1,\n",
        "                     follow_with_bn=True, activation_fn=lambda: nn.ReLU(True), affine=True):\n",
        "    assert layers > 0 and kernel_size % 2 > 0 and stride > 0\n",
        "    current_channels = in_channels\n",
        "    _modules = []\n",
        "    for layer in range(layers):\n",
        "        _modules.append(nn.Conv2d(current_channels, out_channels, kernel_size=kernel_size,\n",
        "                                  stride=stride if layer == 0 else 1,\n",
        "                                  padding=kernel_size // 2, bias=not follow_with_bn))\n",
        "        current_channels = out_channels\n",
        "        if follow_with_bn:\n",
        "            _modules.append(nn.BatchNorm2d(current_channels, affine=affine))\n",
        "        if activation_fn is not None:\n",
        "            _modules.append(activation_fn())\n",
        "    return nn.Sequential(*_modules)\n",
        "\n",
        "\n",
        "def bottleneck_block(in_channels, out_channels, stride=1, layers=1,\n",
        "                     activation_fn=lambda: torch.nn.ReLU(inplace=False)):\n",
        "    assert layers > 0 and stride > 0\n",
        "    current_channels = in_channels\n",
        "    _modules = []\n",
        "    for layer in range(layers):\n",
        "        _modules.append(Bottleneck_(current_channels, out_channels, stride=stride if layer == 0 else 1,\n",
        "                                   activation_fn=activation_fn))\n",
        "        current_channels = out_channels\n",
        "    return nn.Sequential(*_modules) if len(_modules) > 1 else _modules[0]\n",
        "\n",
        "\n",
        "class PixelShuffleBlock(nn.Module):\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.pixel_shuffle(x, 2)\n",
        "\n",
        "\n",
        "def simple_upsampler_subpixel(in_channels, out_channels, kernel_size=3,\n",
        "                              activation_fn=lambda: torch.nn.ReLU(inplace=True),\n",
        "                              follow_with_bn=True):\n",
        "    _modules = [\n",
        "        simple_cnn_block(in_channels, out_channels * 4, kernel_size=kernel_size,\n",
        "                         follow_with_bn=follow_with_bn),\n",
        "        PixelShuffleBlock(),\n",
        "        activation_fn(),\n",
        "    ]\n",
        "    return nn.Sequential(*_modules)\n",
        "\n",
        "\n",
        "class UNetUpsampler(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, passthrough_channels, follow_up_residual_blocks=1,\n",
        "                 upsampler_block=simple_upsampler_subpixel, upsampler_kernel_size=3, activation_fn=lambda: torch.nn.ReLU(inplace=False)):\n",
        "        super(UNetUpsampler, self).__init__()\n",
        "        assert follow_up_residual_blocks >= 1\n",
        "        assert passthrough_channels >= 1\n",
        "        self.upsampler = upsampler_block(in_channels=in_channels,\n",
        "                                         out_channels=out_channels,\n",
        "                                         kernel_size=upsampler_kernel_size,\n",
        "                                         activation_fn=activation_fn)\n",
        "        self.follow_up = bottleneck_block(out_channels + passthrough_channels, out_channels,\n",
        "                                    layers=follow_up_residual_blocks, activation_fn=activation_fn)\n",
        "\n",
        "    def forward(self, inp, passthrough):\n",
        "        upsampled = self.upsampler(inp)\n",
        "        upsampled = torch.cat([upsampled, passthrough], 1)\n",
        "        return self.follow_up(upsampled)\n",
        "\n",
        "\n",
        "class RTSaliencyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, encoder_scales, encoder_base, upsampler_scales,\n",
        "                 upsampler_base, fix_encoder=True, use_simple_activation=False,\n",
        "                 allow_selector=False, num_classes=1000):\n",
        "        super(RTSaliencyModel, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.upsampler_scales = upsampler_scales\n",
        "        self.encoder_scales = encoder_scales\n",
        "        self.fix_encoder = fix_encoder\n",
        "        self.use_simple_activation = use_simple_activation\n",
        "\n",
        "        down = self.encoder_scales\n",
        "        modulator_size = []\n",
        "        for up in reversed(range(self.upsampler_scales)):\n",
        "            upsampler_chans = upsampler_base * 2 ** (up + 1)\n",
        "            encoder_chans = encoder_base * 2 ** down\n",
        "            inc = upsampler_chans if down != encoder_scales else encoder_chans\n",
        "            modulator_size.append(inc)\n",
        "            self.add_module(\"up%d\" % up,\n",
        "                            UNetUpsampler(\n",
        "                                in_channels=inc,\n",
        "                                passthrough_channels=encoder_chans // 2,\n",
        "                                out_channels=upsampler_chans // 2,\n",
        "                                follow_up_residual_blocks=1,\n",
        "                                activation_fn=lambda: nn.ReLU(),\n",
        "                            ))\n",
        "\n",
        "            down -= 1\n",
        "\n",
        "        self.to_saliency_chans = nn.Conv2d(upsampler_base, 2, 1)\n",
        "\n",
        "        self.allow_selector = allow_selector\n",
        "\n",
        "        if self.allow_selector:\n",
        "            s = encoder_base * 2 ** encoder_scales\n",
        "            self.selector_module = nn.Embedding(num_classes, s)\n",
        "            normal_(self.selector_module.weight, 0, 1. / s ** 0.5)\n",
        "\n",
        "    def get_trainable_parameters(self):\n",
        "        all_params = self.parameters()\n",
        "        if not self.fix_encoder: return set(all_params)\n",
        "        unwanted = self.encoder.parameters()\n",
        "        return set(all_params) - set(unwanted) - (set(self.selector_module.parameters() if self.allow_selector\n",
        "                                                      else set()))\n",
        "\n",
        "    def forward(self, _images, _selectors=None, pt_store=None, model_confidence=0.):\n",
        "        out = self.encoder(_images)\n",
        "        if self.fix_encoder:\n",
        "            out = [e.detach() for e in out]\n",
        "\n",
        "        down = self.encoder_scales\n",
        "        main_flow = out[down]\n",
        "\n",
        "        if self.allow_selector:\n",
        "            assert _selectors is not None\n",
        "            em = torch.squeeze(self.selector_module(_selectors.view(-1, 1)), 1)\n",
        "            act = torch.sum(main_flow * em.view(-1, 2048, 1, 1), 1, keepdim=True)\n",
        "            th = torch.sigmoid(act - model_confidence)\n",
        "            main_flow = main_flow * th\n",
        "\n",
        "            ex = torch.mean(torch.mean(act, 3), 2)\n",
        "            exists_logits = torch.cat((-ex / 2., ex / 2.), 1)\n",
        "        else:\n",
        "            exists_logits = None\n",
        "\n",
        "        for up in reversed(range(self.upsampler_scales)):\n",
        "            assert down > 0\n",
        "            main_flow = self._modules['up%d' % up](main_flow, out[down - 1])\n",
        "            down -= 1\n",
        "        saliency_chans = self.to_saliency_chans(main_flow)\n",
        "\n",
        "        if self.use_simple_activation:\n",
        "            return torch.unsqueeze(torch.sigmoid(saliency_chans[:, 0, :, :] / 2), dim=1), exists_logits, out[-1]\n",
        "\n",
        "        a = torch.abs(saliency_chans[:, 0, :, :])\n",
        "        b = torch.abs(saliency_chans[:, 1, :, :])\n",
        "        return torch.unsqueeze(a / (a + b), dim=1), exists_logits, out[-1]\n",
        "\n",
        "    def minimialistic_restore(self, save_dir):\n",
        "        # assert self.fix_encoder, 'You should not use this function if you are not using a pre-trained encoder like resnet'\n",
        "\n",
        "        p = os.path.join(save_dir, 'model-%d.ckpt' % 1)\n",
        "        if not os.path.exists(p):\n",
        "            raise FileNotFoundError('Could not find any checkpoint at %s, skipping restore' % p)\n",
        "        for name, data in torch.load(p, map_location=lambda storage, loc: storage).items():\n",
        "            self._modules[name].load_state_dict(data)\n",
        "\n",
        "    def minimalistic_save(self, save_dir):\n",
        "        assert self.fix_encoder, 'You should not use this function if you are not using a pre-trained encoder like resnet'\n",
        "        data = {}\n",
        "        for name, module in self._modules.items():\n",
        "            if module is self.encoder:  # we do not want to restore the encoder as it should have its own restore function\n",
        "                continue\n",
        "            data[name] = module.state_dict()\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        torch.save(data, os.path.join(save_dir, 'model-%d.ckpt' % 1))\n",
        "\n",
        "\n",
        "def _gaussian_kernels(kernel_size, sigma, chans):\n",
        "    assert kernel_size % 2, 'Kernel size of the gaussian blur must be odd!'\n",
        "    x = np.expand_dims(np.array(range(-kernel_size // 2, -kernel_size // 2 + kernel_size, 1)), 0)\n",
        "    vals = np.exp(-np.square(x) / (2.*sigma**2))\n",
        "    _kernel = np.reshape(vals / np.sum(vals), (1, 1, kernel_size, 1))\n",
        "    kernel = np.zeros((chans, 1, kernel_size, 1), dtype=np.float32) + _kernel\n",
        "    return kernel, np.transpose(kernel, [0, 1, 3, 2])\n",
        "\n",
        "\n",
        "def gaussian_blur(_images, kernel_size=55, sigma=11):\n",
        "    ''' Very fast, linear time gaussian blur, using separable convolution. Operates on batch of images [N, C, H, W].\n",
        "    Returns blurred images of the same size. Kernel size must be odd.\n",
        "    Increasing kernel size over 4*simga yields little improvement in quality. So kernel size = 4*sigma is a good choice.'''\n",
        "    kernel_a, kernel_b = _gaussian_kernels(kernel_size=kernel_size, sigma=sigma, chans=_images.size(1))\n",
        "    kernel_a = torch.Tensor(kernel_a)\n",
        "    kernel_b = torch.Tensor(kernel_b)\n",
        "    if _images.is_cuda:\n",
        "        kernel_a = kernel_a.cuda()\n",
        "        kernel_b = kernel_b.cuda()\n",
        "    _rows = F.conv2d(_images, kernel_a, groups=_images.size(1), padding=(kernel_size // 2, 0))\n",
        "    return F.conv2d(_rows, kernel_b, groups=_images.size(1), padding=(0, kernel_size // 2))\n",
        "\n",
        "\n",
        "def apply_mask(images, mask, noise=True, random_colors=True, blurred_version_prob=0.5, noise_std=0.11,\n",
        "               color_range=0.66, blur_kernel_size=55, blur_sigma=11,\n",
        "               bypass=0., boolean=False, preserved_imgs_noise_std=0.03):\n",
        "    images = images.clone()\n",
        "    cuda = images.is_cuda\n",
        "\n",
        "    if boolean:\n",
        "        # remember its just for validation!\n",
        "        return (mask > 0.5).float() *images\n",
        "\n",
        "    assert 0. <= bypass < 0.9\n",
        "    n, c, _, _ = images.size()\n",
        "    if preserved_imgs_noise_std > 0:\n",
        "        images = images + torch.empty_like(images).normal_(std=preserved_imgs_noise_std)\n",
        "    if bypass > 0:\n",
        "        mask = (1.-bypass)*mask + bypass\n",
        "    if noise and noise_std:\n",
        "        alt = torch.empty_like(images).normal_(std=noise_std)\n",
        "    else:\n",
        "        alt = torch.zeros_like(images)\n",
        "    if random_colors:\n",
        "        if cuda:\n",
        "            alt += torch.Tensor(n, c, 1, 1).cuda().uniform_(-color_range/2., color_range/2.)\n",
        "        else:\n",
        "            alt += torch.Tensor(n, c, 1, 1).uniform_(-color_range/2., color_range/2.)\n",
        "\n",
        "    if blurred_version_prob > 0.: # <- it can be a scalar between 0 and 1\n",
        "        cand = gaussian_blur(images, kernel_size=blur_kernel_size, sigma=blur_sigma)\n",
        "        if cuda:\n",
        "            when =(torch.Tensor(n, 1, 1, 1).cuda().uniform_(0., 1.) < blurred_version_prob).float()\n",
        "        else:\n",
        "            when =(torch.Tensor(n, 1, 1, 1).uniform_(0., 1.) < blurred_version_prob).float()\n",
        "        alt = alt * (1. - when) + cand * when\n",
        "\n",
        "    return (mask * images.detach()) + (1. - mask) * alt.detach()\n",
        "\n",
        "\n",
        "def calc_smoothness_loss(mask, power=2, border_penalty=0.3):\n",
        "    ''' For a given image this loss should be more or less invariant to image resize when using power=2...\n",
        "        let L be the length of a side\n",
        "        EdgesLength ~ L\n",
        "        EdgesSharpness ~ 1/L, easy to see if you imagine just a single vertical edge in the whole image'''\n",
        "    x_loss = torch.sum((torch.abs(mask[:, :, 1:, :] - mask[:, :, :-1, :])) ** power)\n",
        "    y_loss = torch.sum((torch.abs(mask[:, :, :, 1:] - mask[:, :, :, :-1])) ** power)\n",
        "    if border_penalty > 0:\n",
        "        border = (float(border_penalty) * torch.sum(mask[:, :, -1, :] ** power +\n",
        "                                                    mask[:, :, 0, :] ** power +\n",
        "                                                    mask[:, :, :, -1] ** power + mask[:, :, :, 0]**power))\n",
        "    else:\n",
        "        border = 0.\n",
        "    return (x_loss + y_loss + border) / float(power * mask.size(0))  # watch out, normalised by the batch size!\n",
        "\n",
        "\n",
        "def calc_area_loss(mask, power=1.):\n",
        "    if power != 1:\n",
        "        mask = (mask + 0.0005) ** power # prevent nan (derivative of sqrt at 0 is inf)\n",
        "    return torch.mean(mask)\n",
        "\n",
        "\n",
        "def cw_loss(logits, one_hot_labels, targeted=True, t_conf=2, nt_conf=5):\n",
        "    ''' computes the advantage of the selected label over other highest prob guess.\n",
        "        In case of the targeted it tries to maximise this advantage to reach desired confidence.\n",
        "        For example confidence of 3 would mean that the desired label is e^3 (about 20) times more probable than the second top guess.\n",
        "        In case of non targeted optimisation the case is opposite and we try to minimise this advantage - the probability of the label is\n",
        "        20 times smaller than the probability of the top guess.\n",
        "        So for targeted optim a small confidence should be enough (about 2) and for non targeted about 5-6 would work better (assuming 1000 classes so log(no_idea)=6.9)\n",
        "    '''\n",
        "    this = torch.sum(logits*one_hot_labels, 1)\n",
        "    other_best, _ = torch.max(logits*(1.-one_hot_labels) - 12111*one_hot_labels, 1)   # subtracting 12111 from selected labels to make sure that they dont end up a maximum\n",
        "    t = F.relu(other_best - this + t_conf)\n",
        "    nt = F.relu(this - other_best + nt_conf)\n",
        "    if isinstance(targeted, (bool, int)):\n",
        "        return torch.mean(t) if targeted else torch.mean(nt)\n",
        "    else:  # must be a byte tensor of zeros and ones\n",
        "\n",
        "        return torch.mean(t*(targeted>0).float() + nt*(targeted==0).float())\n",
        "\n",
        "\n",
        "def one_hot(labels, depth):\n",
        "    if labels.is_cuda:\n",
        "        return torch.zeros(labels.size(0), depth).cuda().scatter_(1, labels.long().view(-1, 1).data, 1)\n",
        "    else:\n",
        "        return torch.zeros(labels.size(0), depth).scatter_(1, labels.long().view(-1, 1).data, 1)\n",
        "\n",
        "\n",
        "class SaliencyLoss:\n",
        "    def __init__(self, black_box_fn, area_loss_coef=8, smoothness_loss_coef=0.5, preserver_loss_coef=0.3,\n",
        "                 num_classes=1000, area_loss_power=0.3, preserver_confidence=1, destroyer_confidence=5, **apply_mask_kwargs):\n",
        "        self.black_box_fn = black_box_fn\n",
        "        self.area_loss_coef = area_loss_coef\n",
        "        self.smoothness_loss_coef = smoothness_loss_coef\n",
        "        self.preserver_loss_coef = preserver_loss_coef\n",
        "        self.num_classes = num_classes\n",
        "        self.area_loss_power =area_loss_power\n",
        "        self.preserver_confidence = preserver_confidence\n",
        "        self.destroyer_confidence = destroyer_confidence\n",
        "        self.apply_mask_kwargs = apply_mask_kwargs\n",
        "\n",
        "    def get_loss(self, _images, _targets, _masks, _is_real_target=None, pt_store=None):\n",
        "        ''' masks must be already in the range 0,1 and of shape:  (B, 1, ?, ?)'''\n",
        "        if _masks.size()[-2:] != _images.size()[-2:]:\n",
        "            _masks = F.upsample(_masks, (_images.size(2), _images.size(3)), mode='bilinear')\n",
        "\n",
        "        if _is_real_target is None:\n",
        "            _is_real_target = torch.ones_like(_targets)\n",
        "        destroyed_images = apply_mask(_images, 1.-_masks, **self.apply_mask_kwargs)\n",
        "        destroyed_logits = self.black_box_fn(destroyed_images)\n",
        "\n",
        "        preserved_images = apply_mask(_images, _masks, **self.apply_mask_kwargs)\n",
        "        preserved_logits = self.black_box_fn(preserved_images)\n",
        "\n",
        "        _one_hot_targets = one_hot(_targets, self.num_classes)\n",
        "        preserver_loss = cw_loss(preserved_logits, _one_hot_targets, targeted=_is_real_target == 1, t_conf=self.preserver_confidence, nt_conf=1.)\n",
        "        destroyer_loss = cw_loss(destroyed_logits, _one_hot_targets, targeted=_is_real_target == 0, t_conf=1., nt_conf=self.destroyer_confidence)\n",
        "        area_loss = calc_area_loss(_masks, self.area_loss_power)\n",
        "        smoothness_loss = calc_smoothness_loss(_masks)\n",
        "\n",
        "        total_loss = destroyer_loss + self.area_loss_coef*area_loss + self.smoothness_loss_coef*smoothness_loss + self.preserver_loss_coef*preserver_loss\n",
        "\n",
        "        if pt_store is not None:\n",
        "            # add variables to the pt_store\n",
        "            pt_store(masks=_masks)\n",
        "            pt_store(destroyed=destroyed_images)\n",
        "            pt_store(preserved=preserved_images)\n",
        "            pt_store(area_loss=area_loss)\n",
        "            pt_store(smoothness_loss=smoothness_loss)\n",
        "            pt_store(destroyer_loss=destroyer_loss)\n",
        "            pt_store(preserver_loss=preserver_loss)\n",
        "            pt_store(preserved_logits=preserved_logits)\n",
        "            pt_store(destroyed_logits=destroyed_logits)\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "def to_batch_variable(x, required_rank, cuda=False):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        if cuda and not x.is_cuda:\n",
        "            return x.cuda()\n",
        "        if not cuda and x.is_cuda:\n",
        "            return x.cpu()\n",
        "        else:\n",
        "            return x\n",
        "    if isinstance(x, (float, int)):\n",
        "        assert required_rank == 1\n",
        "        return to_batch_variable(np.array([x]), required_rank, cuda)\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return to_batch_variable(np.array(x), required_rank, cuda)\n",
        "    if isinstance(x, np.ndarray):\n",
        "        c = len(x.shape)\n",
        "        if c == required_rank:\n",
        "            return to_batch_variable(torch.from_numpy(x), required_rank, cuda)\n",
        "        elif c + 1 == required_rank:\n",
        "            return to_batch_variable(torch.unsqueeze(torch.from_numpy(x), dim=0), required_rank, cuda)\n",
        "        else:\n",
        "            raise ValueError()\n",
        "\n",
        "\n",
        "def get_pretrained_saliency_fn(ckpt_dir, cuda=True, return_classification_logits=False):\n",
        "    ''' returns a saliency function that takes images and class selectors as inputs. If cuda=True then places the model on a GPU.\n",
        "    You can also specify model_confidence - smaller values (~0) will show any object in the image that even slightly resembles the specified class\n",
        "    while higher values (~5) will show only the most salient parts.\n",
        "    Params of the saliency function:\n",
        "    images - input images of shape (C, H, W) or (N, C, H, W) if in batch. Can be either a numpy array, a Tensor or a Variable\n",
        "    selectors - class ids to be masked. Can be either an int or an array with N integers. Again can be either a numpy array, a Tensor or a Variable\n",
        "    model_confidence - a float, 6 by default, you may want to decrease this value to obtain more complete saliency maps.\n",
        "    returns a Variable of shape (N, 1, H, W) with one saliency maps for each input image.\n",
        "    '''\n",
        "    saliency = RTSaliencyModel(resnet50encoder(pretrained=True), 5, 64, 3, 64, fix_encoder=False, use_simple_activation=False, allow_selector=True)\n",
        "    saliency.minimialistic_restore(ckpt_dir)\n",
        "    saliency.train(False)\n",
        "    if cuda:\n",
        "        saliency = saliency.cuda()\n",
        "\n",
        "    def saliency_fn(images, selectors, model_confidence=6):\n",
        "        _images, _selectors = to_batch_variable(images, 4, cuda), to_batch_variable(selectors, 1, cuda).long()\n",
        "        masks, _, cls_logits = saliency(_images * 2, _selectors, model_confidence=model_confidence)\n",
        "        sal_map = F.upsample(masks, (_images.size(2), _images.size(3)), mode='bilinear')\n",
        "        if not return_classification_logits:\n",
        "            return sal_map\n",
        "        return sal_map, cls_logits\n",
        "\n",
        "    def logits_fn(images):\n",
        "        _images = to_batch_variable(images, 4, cuda)\n",
        "        logits = saliency.encoder(_images * 2)[-1]\n",
        "        return logits\n",
        "\n",
        "    return saliency_fn, logits_fn\n",
        "\n",
        "\n",
        "def read_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.transpose(img[..., ::-1], [2, 0, 1])\n",
        "    img = np.float32(img) / 255. * 2 - 1\n",
        "    return to_batch_variable(img, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ZtGWt1H1SL"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import densenet169\n",
        "\n",
        "\n",
        "class RTSDensenet169(object):\n",
        "\n",
        "    def __init__(self, ckpt_dir, cuda, blackbox_model=None, pre_fn=None):\n",
        "        self.saliency = RTSaliencyModel(resnet50encoder(pretrained=True), 5, 64, 3, 64, fix_encoder=False, use_simple_activation=False, allow_selector=True)\n",
        "#         self.saliency.minimialistic_restore(ckpt_dir)\n",
        "        self.saliency.train(False)\n",
        "        if cuda:\n",
        "            self.saliency.cuda()\n",
        "\n",
        "        if blackbox_model is None:\n",
        "            blackbox_model = densenet169(pretrained=True)\n",
        "            self.blackbox_model = blackbox_model\n",
        "            self.blackbox_model.train(False)\n",
        "            if cuda:\n",
        "                self.blackbox_model.cuda()\n",
        "        else:\n",
        "            self.blackbox_model = blackbox_model\n",
        "        self.pre_fn = imagenet_normalize if pre_fn is None else pre_fn\n",
        "\n",
        "    def saliency_fn(self, x, y, model_confidence=6, return_classification_logits=False):\n",
        "        masks, _, cls_logits = self.saliency(imagenet_normalize(x), y,\n",
        "                                             model_confidence=model_confidence)\n",
        "        # sal_map = F.upsample(masks, (x.size(2), x.size(3)), mode='bilinear')\n",
        "        if not return_classification_logits:\n",
        "            return masks\n",
        "        return masks, cls_logits\n",
        "\n",
        "    def logits_fn(self, x):\n",
        "        logits = self.saliency.encoder(imagenet_normalize(x))[-1]\n",
        "        return logits\n",
        "\n",
        "    def blackbox_logits_fn(self, x):\n",
        "        return self.blackbox_model(self.pre_fn(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpWGgnSnH6E7"
      },
      "outputs": [],
      "source": [
        "class RTSResnet50(object):\n",
        "\n",
        "    def __init__(self, ckpt_dir, cuda, blackbox_model=None, pre_fn=None):\n",
        "        self.saliency = RTSaliencyModel(resnet50encoder(pretrained=True), 5, 64, 3, 64, fix_encoder=False, use_simple_activation=False, allow_selector=True)\n",
        "        # self.saliency.minimialistic_restore(ckpt_dir)\n",
        "        self.saliency.train(False)\n",
        "        if cuda:\n",
        "            self.saliency.cuda()\n",
        "\n",
        "        if blackbox_model is None:\n",
        "            blackbox_model = resnet50(pretrained=True)\n",
        "            self.blackbox_model = blackbox_model\n",
        "            self.blackbox_model.train(False)\n",
        "            if cuda:\n",
        "                self.blackbox_model.cuda()\n",
        "        else:\n",
        "            self.blackbox_model = blackbox_model\n",
        "        self.pre_fn = imagenet_normalize if pre_fn is None else pre_fn\n",
        "\n",
        "    def saliency_fn(self, x, y, model_confidence=6, return_classification_logits=False):\n",
        "        masks, _, cls_logits = self.saliency((x - 0.5) * 4, y, model_confidence=model_confidence)\n",
        "        # sal_map = F.upsample(masks, (x.size(2), x.size(3)), mode='bilinear')\n",
        "        if not return_classification_logits:\n",
        "            return masks\n",
        "        return masks, cls_logits\n",
        "\n",
        "    def logits_fn(self, x):\n",
        "        logits = self.saliency.encoder((x - 0.5) * 4)[-1]\n",
        "        return logits\n",
        "\n",
        "    def blackbox_logits_fn(self, x):\n",
        "        return self.blackbox_model(self.pre_fn(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhM4F-MBH8n6"
      },
      "outputs": [],
      "source": [
        "def get_default_rts_config(model):\n",
        "    if model == 'resnet50':\n",
        "        return dict(ckpt_dir='', batch_size=10, model_confidence=5)\n",
        "    if model == 'densenet169':\n",
        "        return dict(ckpt_dir='', batch_size=10, model_confidence=5)\n",
        "\n",
        "\n",
        "def generate_rts_per_batch(rts_config, rts_model, batch_tup, cuda):\n",
        "    bx, by = batch_tup\n",
        "    bx, by = torch.tensor(bx), torch.tensor(by)\n",
        "    if cuda:\n",
        "        bx, by = bx.cuda(), by.cuda()\n",
        "    return rts_model.saliency_fn(bx, by, model_confidence=rts_config['model_confidence'],\n",
        "                                 return_classification_logits=False)\n",
        "\n",
        "\n",
        "def generate_rts(rts_config, rts_model, images_tup, cuda):\n",
        "    img_x, img_y = images_tup[:2]\n",
        "    batch_size = rts_config['batch_size']\n",
        "    num_batches = (len(img_x) + batch_size - 1) // batch_size\n",
        "\n",
        "    rts = []\n",
        "    for i in range(num_batches):\n",
        "        start_index = i * batch_size\n",
        "        end_index = min(len(img_x), start_index + batch_size)\n",
        "        bx, by = img_x[start_index:end_index], img_y[start_index:end_index]\n",
        "        rts.append(generate_rts_per_batch(rts_config, rts_model, (bx, by), cuda).detach().cpu().numpy())\n",
        "\n",
        "    rts = np.concatenate(rts, axis=0)\n",
        "    return rts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge"
      ],
      "metadata": {
        "id": "ixpc_v1OS35l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSzXltreIFby"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "def load_model(config):\n",
        "    if config['model'] == 'resnet50':\n",
        "        model_tup, forward_tup = cam_resnet50()\n",
        "    if config['model'] == 'densenet169':\n",
        "        model_tup, forward_tup = cam_densenet169()\n",
        "    model = model_tup[0]\n",
        "    freeze_model(model)\n",
        "    model.train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model.cuda()\n",
        "    return model_tup, forward_tup\n",
        "\n",
        "def tanh_space(x):\n",
        "    return 1/2*(torch.tanh(x) + 1)\n",
        "\n",
        "def inverse_tanh_space(x):\n",
        "    return atanh(x*2-1)\n",
        "\n",
        "def atanh(x):\n",
        "    return 0.5*torch.log((1+x)/(1-x))\n",
        "\n",
        "def f(outputs, labels, kappa):\n",
        "    one_hot_labels = torch.eye(len(outputs[0]))[labels.cpu()].to('cuda')\n",
        "    i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
        "    j = torch.masked_select(outputs, one_hot_labels.bool())\n",
        "\n",
        "    # if self._targeted:\n",
        "    return torch.clamp((i-j), min=-kappa)\n",
        "    # else:\n",
        "    #     return torch.clamp((j-i), min=-self.kappa)\n",
        "\n",
        "def attack_batch(config, rts_model, batch_tup, rts_benign):\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(rts_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    bx_adv = bx.clone().detach().requires_grad_()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    w = inverse_tanh_space(bx.clone().detach()).detach()\n",
        "    w.requires_grad_()\n",
        "\n",
        "    best_adv_images = bx.clone().detach()\n",
        "    best_L2 = 1e10*torch.ones((len(bx))).to('cuda')\n",
        "    prev_cost = 1e10\n",
        "    dim = len(bx.shape)\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "\n",
        "    dobj = {}\n",
        "\n",
        "    MSELoss = nn.MSELoss(reduction='none')\n",
        "    Flatten = nn.Flatten()\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = tanh_space(w)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + pert\n",
        "\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "        f_loss = f(logits, by, config['kappa']).sum()\n",
        "\n",
        "        cost = L2_loss + 1e-4*f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "\n",
        "        conf_base = 0.95 + i / config['s2_iters'] * 0.04\n",
        "        conf = np.random.uniform(conf_base, 1, size=(batch_size, )).astype(np.float32)\n",
        "        conf_mat = ((1 - conf) / 9.).reshape((batch_size, 1)).repeat(1000, 1)\n",
        "        conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "        by_one = torch.tensor(conf_mat, device='cuda')\n",
        "\n",
        "        c_now += c_inc\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        rts, rts_logits = rts_model.saliency_fn(adv_images, by, model_confidence=5, return_classification_logits=True)\n",
        "        diff = rts - m0\n",
        "        loss_rts = torch.sum((diff * diff).view(batch_size, -1).mean(1))\n",
        "        logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "        loss_adv =  (-by_one * F.log_softmax(logits)).sum()\n",
        "        rts_adv_loss = F.nll_loss(rts_logits, by, reduction='sum')\n",
        "        loss = 0.5 * rts_adv_loss + L2_loss + c_now *loss_rts + 2 * loss_adv\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_rts_mu = np.asscalar(loss_rts) / batch_size\n",
        "                loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                loss_adv = loss_adv_mu\n",
        "                loss_rts = loss_rts_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss rts: %.5f, succeed: %d' % (i, loss_adv, loss_rts, num_succeed))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    rts = rts_model.saliency_fn(adv_images, by, model_confidence=5, return_classification_logits=False)\n",
        "    logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "\n",
        "    dobj['adv_x' ] = adv_images.detach().cpu().numpy()\n",
        "    dobj['adv_rts'] = rts.detach().cpu().numpy()\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['trts'] = rts_benign\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "    rts_model = RTSDensenet169('', config['device'] == 'gpu')\n",
        "    freeze_model(rts_model.blackbox_model)\n",
        "    freeze_model(rts_model.saliency)\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    rts_target = data_arx['saliency_benign_yt']\n",
        "    rts_benign = data_arx['saliency_benign_y']\n",
        "\n",
        "# ['saliency_benign_y', 'saliency_benign_yt', 'img_x', 'img_y', 'img_yt']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], rts_target[si:ei]\n",
        "        dobj = attack_batch(config, rts_model, (bx, byt), bm0)\n",
        "        dobj['brts'] = rts_benign[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_x'] = img_x\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_rts_1(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 1000\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "    config['kappa'] = 0\n",
        "    config['tau'] = 0.0005\n",
        "\n",
        "#     if (not os.path.exists(config['save_path'])):\n",
        "#       os.mkdir(config['save_path'])\n",
        "#     config['save_path'] += fName\n",
        "\n",
        "\n",
        "    if config['device'] is None:\n",
        "        if torch.cuda.is_available():\n",
        "            config['device'] = 'gpu'\n",
        "        else:\n",
        "            config['device'] = 'cpu'\n",
        "    attack(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xGbqzWOaIGy6"
      },
      "outputs": [],
      "source": [
        "attack_rts_1('rts.npz', 'output_1.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge+"
      ],
      "metadata": {
        "id": "vh_RzrzeTGMe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIci6ueeTpgE"
      },
      "outputs": [],
      "source": [
        "def attack_batch(config, rts_model, batch_tup, rts_benign):\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(rts_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    bx_adv = bx.clone().detach().requires_grad_()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    w = inverse_tanh_space(bx.clone().detach()).detach()\n",
        "    w.requires_grad_()\n",
        "\n",
        "    best_adv_images = bx.clone().detach()\n",
        "    best_L2 = 1e10*torch.ones((len(bx))).to('cuda')\n",
        "    prev_cost = 1e10\n",
        "    dim = len(bx.shape)\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "\n",
        "    dobj = {}\n",
        "\n",
        "    MSELoss = nn.MSELoss(reduction='none')\n",
        "    Flatten = nn.Flatten()\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = tanh_space(w)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + torch.where(weights > 0.1, pert, torch.tensor(0.).to('cuda'))\n",
        "\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "        f_loss = f(logits, by, config['kappa']).sum()\n",
        "\n",
        "        cost = L2_loss + 1e-4*f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "\n",
        "        conf_base = 0.95 + i / config['s2_iters'] * 0.04\n",
        "        conf = np.random.uniform(conf_base, 1, size=(batch_size, )).astype(np.float32)\n",
        "        conf_mat = ((1 - conf) / 9.).reshape((batch_size, 1)).repeat(1000, 1)\n",
        "        conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "        by_one = torch.tensor(conf_mat, device='cuda')\n",
        "\n",
        "        c_now += c_inc\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        rts, rts_logits = rts_model.saliency_fn(adv_images, by, model_confidence=5, return_classification_logits=True)\n",
        "        diff = rts - m0\n",
        "        loss_rts = torch.sum((diff * diff).view(batch_size, -1).mean(1))\n",
        "        logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "        loss_adv =  (-by_one * F.log_softmax(logits)).sum()\n",
        "        rts_adv_loss = F.nll_loss(rts_logits, by, reduction='sum')\n",
        "        loss = 0.5 * rts_adv_loss + L2_loss + c_now *loss_rts + 2 * loss_adv\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_rts_mu = np.asscalar(loss_rts) / batch_size\n",
        "                loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                loss_adv = loss_adv_mu\n",
        "                loss_rts = loss_rts_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss rts: %.5f, succeed: %d' % (i, loss_adv, loss_rts, num_succeed))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    rts = rts_model.saliency_fn(adv_images, by, model_confidence=5, return_classification_logits=False)\n",
        "    logits = rts_model.blackbox_logits_fn(adv_images)\n",
        "\n",
        "    dobj['adv_x' ] = adv_images.detach().cpu().numpy()\n",
        "    dobj['adv_rts'] = rts.detach().cpu().numpy()\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['trts'] = rts_benign\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "    rts_model = RTSDensenet169('', config['device'] == 'gpu')\n",
        "    freeze_model(rts_model.blackbox_model)\n",
        "    freeze_model(rts_model.saliency)\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    rts_target = data_arx['saliency_benign_yt']\n",
        "    rts_benign = data_arx['saliency_benign_y']\n",
        "\n",
        "# ['saliency_benign_y', 'saliency_benign_yt', 'img_x', 'img_y', 'img_yt']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], rts_target[si:ei]\n",
        "        dobj = attack_batch(config, rts_model, (bx, byt), bm0)\n",
        "        dobj['brts'] = rts_benign[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_x'] = img_x\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_rts_2(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 1000\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "    config['kappa'] = 0\n",
        "    config['tau'] = 0.0005\n",
        "\n",
        "#     if (not os.path.exists(config['save_path'])):\n",
        "#       os.mkdir(config['save_path'])\n",
        "#     config['save_path'] += fName\n",
        "\n",
        "\n",
        "    if config['device'] is None:\n",
        "        if torch.cuda.is_available():\n",
        "            config['device'] = 'gpu'\n",
        "        else:\n",
        "            config['device'] = 'cpu'\n",
        "    attack(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_rts_2('rts.npz', 'output_1.npz')"
      ],
      "metadata": {
        "id": "TME2WxVWTPIs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Tdb_XbsTUfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}