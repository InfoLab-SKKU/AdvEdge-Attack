{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF5gutN_IO6I"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "import time\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct9KeJSVLD8w"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.set_device(1)\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KPV0xyYIlOJ"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BGYBLxpInX4"
      },
      "outputs": [],
      "source": [
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8aFx5WlIqBn"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO0v3PM8JRAQ"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = SoftReLU()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = SoftReLU()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = SoftReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet50_soft(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myUBAATAIr3I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class StadvTVLoss(nn.Module):\n",
        "\n",
        "    def forward(self, flows):\n",
        "        padded_flows = F.pad(flows, (1, 1, 1, 1), mode='replicate')\n",
        "        height, width = flows.size(2), flows.size(3)\n",
        "        n = float(np.sqrt(height * width))\n",
        "        shifted_flows = [\n",
        "            padded_flows[:, :, 2:, 2:],\n",
        "            padded_flows[:, :, 2:, :-2],\n",
        "            padded_flows[:, :, :-2, 2:],\n",
        "            padded_flows[:, :, :-2, :-2]\n",
        "        ]\n",
        "\n",
        "        diffs = [(flows[:, 1] - shifted_flow[:, 1]) ** 2 + (flows[:, 0] - shifted_flow[:, 0]) ** 2\n",
        "                 for shifted_flow in shifted_flows]\n",
        "        loss = torch.stack(diffs).sum(2, keepdim=True).sum(3, keepdim=True).sum(0, keepdim=True).view(-1)\n",
        "        loss = torch.sqrt(loss)\n",
        "        return loss / n\n",
        "\n",
        "\n",
        "class StadvFlowLoss(nn.Module):\n",
        "\n",
        "    def forward(self,flows, epsilon=1e-8):\n",
        "        padded_flows = F.pad(flows, (1, 1, 1, 1), mode='replicate')\n",
        "        shifted_flows = [\n",
        "            padded_flows[:, :, 2:, 2:],\n",
        "            padded_flows[:, :, 2:, :-2],\n",
        "            padded_flows[:, :, :-2, 2:],\n",
        "            padded_flows[:, :, :-2, :-2]\n",
        "        ]\n",
        "\n",
        "        diffs = [torch.sqrt((flows[:, 1] - shifted_flow[:, 1]) ** 2 +\n",
        "                            (flows[:, 0] - shifted_flow[:, 0]) ** 2 +\n",
        "                            epsilon) for shifted_flow in shifted_flows\n",
        "                 ]\n",
        "        # shape: (4, n, h - 1, w - 1) => (n, )\n",
        "        loss = torch.stack(diffs).sum(2, keepdim=True).sum(3, keepdim=True).sum(0, keepdim=True).view(-1)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class StadvFlow(nn.Module):\n",
        "\n",
        "    def forward(self, images, flows):\n",
        "        batch_size, n_channels, height, width = images.shape\n",
        "        basegrid = torch.stack(torch.meshgrid([torch.arange(height, device=images.device),\n",
        "                                               torch.arange(width, device=images.device)]))\n",
        "        batched_basegrid = basegrid.expand(batch_size, -1, -1, -1)\n",
        "\n",
        "        sampling_grid = batched_basegrid.float() + flows\n",
        "        sampling_grid_x = torch.clamp(sampling_grid[:, 1], 0., float(width) - 1)\n",
        "        sampling_grid_y = torch.clamp(sampling_grid[:, 0], 0., float(height) - 1)\n",
        "\n",
        "        x0 = sampling_grid_x.floor().long()\n",
        "        x1 = x0 + 1\n",
        "        y0 = sampling_grid_y.floor().long()\n",
        "        y1 = y0 + 1\n",
        "\n",
        "        x0.clamp_(0, width - 2)\n",
        "        x1.clamp_(0, width - 1)\n",
        "        y0.clamp_(0, height - 2)\n",
        "        y1.clamp_(0, height - 1)\n",
        "\n",
        "        b = torch.arange(batch_size).view(batch_size, 1, 1).expand(-1, height, width)\n",
        "\n",
        "        Ia = images[b, :, y0, x0].permute(0, 3, 1, 2)\n",
        "        Ib = images[b, :, y1, x0].permute(0, 3, 1, 2)\n",
        "        Ic = images[b, :, y0, x1].permute(0, 3, 1, 2)\n",
        "        Id = images[b, :, y1, x1].permute(0, 3, 1, 2)\n",
        "\n",
        "        x0 = x0.float()\n",
        "        x1 = x1.float()\n",
        "        y0 = y0.float()\n",
        "        y1 = y1.float()\n",
        "\n",
        "        wa = (x1 - sampling_grid_x) * (y1 - sampling_grid_y)\n",
        "        wb = (x1 - sampling_grid_x) * (sampling_grid_y - y0)\n",
        "        wc = (sampling_grid_x - x0) * (y1 - sampling_grid_y)\n",
        "        wd = (sampling_grid_x - x0) * (sampling_grid_y - y0)\n",
        "\n",
        "        wa = wa.unsqueeze(1)\n",
        "        wb = wb.unsqueeze(1)\n",
        "        wc = wc.unsqueeze(1)\n",
        "        wd = wd.unsqueeze(1)\n",
        "\n",
        "        perturbed_image = torch.stack([wa * Ia, wb * Ib, wc * Ic, wd * Id]).sum(0)\n",
        "        return perturbed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBRC2U9pJKk9"
      },
      "source": [
        "### AdvEdge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peNdaHlWJP19"
      },
      "outputs": [],
      "source": [
        "class CAM(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, model_tup, forward_tup, x, y=None):\n",
        "        return cam_forward(model_tup, forward_tup, x, y)\n",
        "\n",
        "\n",
        "def cam_forward(model_tup, forward_tup, x, y):\n",
        "    forward_fn, fc_weight_fn = forward_tup\n",
        "    batch_size = x.size(0)\n",
        "    cuda = x.is_cuda\n",
        "    if y is None:\n",
        "        with torch.no_grad():\n",
        "            logits = forward_fn(model_tup, x)[-1]\n",
        "            logits = logits.cpu().numpy()[0]\n",
        "        true_label = int(np.argmax(logits))\n",
        "        y = torch.tensor([true_label])\n",
        "        if cuda:\n",
        "            y = y.cuda()\n",
        "\n",
        "    vs, gs, logits = forward_fn(model_tup, x)\n",
        "    wc = fc_weight_fn(model_tup)[y].view(batch_size, -1, 1, 1)\n",
        "    prod = (wc * vs).sum(1, keepdim=True)\n",
        "\n",
        "    return logits, prod\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1hGE5r5Dspe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cam_resnet50_forward(model_tup, x):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    res = model(pre_fn(x), out_keys=[\"l4\", \"gvp\", \"fc\"])\n",
        "    return res['l4'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "def cam_resnet50_fc_weight(model_tup):\n",
        "    model = model_tup[0]\n",
        "    return model.fc.weight\n",
        "\n",
        "\n",
        "def cam_resnet50():\n",
        "    model = resnet50(pretrained=True)\n",
        "    model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "    return model_tup, (cam_resnet50_forward, cam_resnet50_fc_weight)\n",
        "\n",
        "\n",
        "def cam_densenet169_forward(model_tup, x):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    res = model(pre_fn(x), out_keys=['l', 'gvp', 'fc'])\n",
        "    return res['l'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "def cam_densenet169_fc_weight(model_tup):\n",
        "    model = model_tup[0]\n",
        "    return model.classifier.weight\n",
        "\n",
        "\n",
        "def cam_densenet169():\n",
        "    model = densenet169(pretrained=True)\n",
        "    model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "    return model_tup, (cam_densenet169_forward, cam_densenet169_fc_weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hGFu5qzO_zg"
      },
      "outputs": [],
      "source": [
        "def load_model(config):\n",
        "    if config['model'] == 'resnet50':\n",
        "        model_tup, forward_tup = cam_resnet50()\n",
        "    if config['model'] == 'densenet169':\n",
        "        model_tup, forward_tup = cam_densenet169()\n",
        "    model = model_tup[0]\n",
        "    freeze_model(model)\n",
        "    model.train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model.cuda()\n",
        "    return model_tup, forward_tup\n",
        "\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model_tup, forward_tup = load_model(config)\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    device = 'cuda' if config['device'] == 'gpu' else 'cpu'\n",
        "    # cuda = config.device == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by, m0 = (torch.tensor(bx_np, device=device), torch.tensor(by_np, device=device),\n",
        "              torch.tensor(cam_benign, device=device))\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    dobj = {}\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    images = bx\n",
        "    flows = 0.2 * (torch.rand(batch_size, 2, images.size(2), images.size(3), device=device) - 0.5)\n",
        "    flows.requires_grad_(True)\n",
        "\n",
        "    tau = config['tau']\n",
        "    flow_obj = StadvFlow()\n",
        "    flow_loss_obj = StadvFlowLoss()\n",
        "    flow_tvloss_obj = StadvTVLoss()\n",
        "    optimizer = Adam([flows], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = flow_obj(images, flows)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + pert\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "        total_loss = adv_loss + tau * flow_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0 or i == config['s1_iters'] - 1:\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_tvloss_obj(flows)\n",
        "                preds = logits.argmax(1)\n",
        "                succeed = (preds == by).float().mean().item()\n",
        "            print('s1-step: %d, average adv loss: %.4f, average flow loss: %.4f, succeed: %.2f' %\n",
        "                  (i, adv_loss.mean().item(), flow_loss.mean().item(), succeed))\n",
        "\n",
        "    optimizer = Adam([flows], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "    for i in range(config['s2_iters']):\n",
        "        c_now += c_inc\n",
        "        adv_images = flow_obj(images, flows)\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "\n",
        "        logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = (diff * diff).mean(1)\n",
        "        total_loss = 2 * adv_loss + tau * flow_loss + c_now * loss_cam\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = loss_cam.mean().item()\n",
        "                loss_adv_mu = adv_loss.mean().item()\n",
        "                flow_loss = flow_tvloss_obj(flows).mean().item()\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                adv_loss = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss flow: %.3f, loss adv: %.2f, loss cam: %.5f, succeed: %d' %\n",
        "                  (i, flow_loss, adv_loss, loss_cam, num_succeed))\n",
        "\n",
        "    logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "    adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "    cam_flatten = cam.view(batch_size, -1)\n",
        "    cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "    cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "    dobj['adv_x'] = adv_images.detach().cpu().numpy()\n",
        "    dobj['adv_cam'] = cam_flatten.detach().cpu().numpy().reshape((batch_size, 1, 7, 7))\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['tcam'] = cam_benign\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam(path, fname):\n",
        "    config = {}\n",
        "    config['data_path'] = path\n",
        "    config['save_path'] = f'{fname}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['model'] = 'resnet50'\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 200\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 600\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['tau'] = 0.0005\n",
        "    config['c'] = 5.\n",
        "\n",
        "    # if(not os.path.exists('cam_attack_output/')):\n",
        "    #   os.mkdir('cam_attack_output')\n",
        "\n",
        "    attack(config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygA_Erg3DU3n",
        "outputId": "7cb8349b-85b1-4963-ebe6-386fc4984c88",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 160MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1-step: 0, average adv loss: 18.4268, average flow loss: 0.1982, succeed: 0.00\n",
            "s1-step: 50, average adv loss: 12.0129, average flow loss: 0.1776, succeed: 0.00\n",
            "s1-step: 100, average adv loss: 9.2591, average flow loss: 0.2579, succeed: 0.00\n",
            "s1-step: 150, average adv loss: 8.3619, average flow loss: 0.2863, succeed: 0.10\n",
            "s1-step: 199, average adv loss: 7.9932, average flow loss: 0.2998, succeed: 0.10\n",
            "s2-step: 0, loss flow: 0.302, loss adv: 8.56, loss cam: 0.14685, succeed: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-4ede969163e8>:97: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2-step: 100, loss flow: 0.224, loss adv: 0.08, loss cam: 0.05930, succeed: 10\n",
            "s2-step: 200, loss flow: 0.189, loss adv: 0.07, loss cam: 0.04824, succeed: 10\n",
            "s2-step: 300, loss flow: 0.178, loss adv: 0.06, loss cam: 0.04282, succeed: 10\n",
            "s2-step: 400, loss flow: 0.174, loss adv: 0.06, loss cam: 0.03923, succeed: 10\n",
            "s2-step: 500, loss flow: 0.171, loss adv: 0.06, loss cam: 0.03636, succeed: 10\n"
          ]
        }
      ],
      "source": [
        "attack_cam('fold_1.npz', 'output_1.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge+"
      ],
      "metadata": {
        "id": "i18xRUbbLnIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGKTZYE-UHcY"
      },
      "outputs": [],
      "source": [
        "def load_model(config):\n",
        "    if config['model'] == 'resnet50':\n",
        "        model_tup, forward_tup = cam_resnet50()\n",
        "    if config['model'] == 'densenet169':\n",
        "        model_tup, forward_tup = cam_densenet169()\n",
        "    model = model_tup[0]\n",
        "    freeze_model(model)\n",
        "    model.train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model.cuda()\n",
        "    return model_tup, forward_tup\n",
        "\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model_tup, forward_tup = load_model(config)\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    device = 'cuda' if config['device'] == 'gpu' else 'cpu'\n",
        "    # cuda = config.device == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by, m0 = (torch.tensor(bx_np, device=device), torch.tensor(by_np, device=device),\n",
        "              torch.tensor(cam_benign, device=device))\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    dobj = {}\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    images = bx\n",
        "    flows = 0.2 * (torch.rand(batch_size, 2, images.size(2), images.size(3), device=device) - 0.5)\n",
        "    flows.requires_grad_(True)\n",
        "\n",
        "    tau = config['tau']\n",
        "    flow_obj = StadvFlow()\n",
        "    flow_loss_obj = StadvFlowLoss()\n",
        "    flow_tvloss_obj = StadvTVLoss()\n",
        "    optimizer = Adam([flows], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = flow_obj(images, flows)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + torch.where(weights > 0.1, pert, torch.tensor(0.).to(device))\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "        total_loss = adv_loss + tau * flow_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0 or i == config['s1_iters'] - 1:\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_tvloss_obj(flows)\n",
        "                preds = logits.argmax(1)\n",
        "                succeed = (preds == by).float().mean().item()\n",
        "            print('s1-step: %d, average adv loss: %.4f, average flow loss: %.4f, succeed: %.2f' %\n",
        "                  (i, adv_loss.mean().item(), flow_loss.mean().item(), succeed))\n",
        "\n",
        "    optimizer = Adam([flows], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "    for i in range(config['s2_iters']):\n",
        "        c_now += c_inc\n",
        "        adv_images = flow_obj(images, flows)\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "\n",
        "        logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = (diff * diff).mean(1)\n",
        "        total_loss = 2 * adv_loss + tau * flow_loss + c_now * loss_cam\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = loss_cam.mean().item()\n",
        "                loss_adv_mu = adv_loss.mean().item()\n",
        "                flow_loss = flow_tvloss_obj(flows).mean().item()\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                adv_loss = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss flow: %.3f, loss adv: %.2f, loss cam: %.5f, succeed: %d' %\n",
        "                  (i, flow_loss, adv_loss, loss_cam, num_succeed))\n",
        "\n",
        "    logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "    adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "    cam_flatten = cam.view(batch_size, -1)\n",
        "    cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "    cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "    dobj['adv_x'] = adv_images.detach().cpu().numpy()\n",
        "    dobj['adv_cam'] = cam_flatten.detach().cpu().numpy().reshape((batch_size, 1, 7, 7))\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['tcam'] = cam_benign\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam_2(path, fname):\n",
        "    config = {}\n",
        "    config['data_path'] = path\n",
        "    config['save_path'] = f'{fname}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['model'] = 'resnet50'\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 200\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 600\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['tau'] = 0.0005\n",
        "    config['c'] = 5.\n",
        "\n",
        "    # if(not os.path.exists('cam_attack_output/')):\n",
        "    #   os.mkdir('cam_attack_output')\n",
        "\n",
        "    attack(config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_cam_2('fold_1.npz', 'output_2.npz')"
      ],
      "metadata": {
        "id": "bx_7y78ML_-v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jO0zniJMB2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}