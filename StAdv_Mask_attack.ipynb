{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SF5gutN_IO6I"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "import time\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-V4U80XXQGNy"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.set_device(1)\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7KPV0xyYIlOJ"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3BGYBLxpInX4"
      },
      "outputs": [],
      "source": [
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8aFx5WlIqBn"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UO0v3PM8JRAQ"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = SoftReLU()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = SoftReLU()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = SoftReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet50_soft(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "myUBAATAIr3I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class StadvTVLoss(nn.Module):\n",
        "\n",
        "    def forward(self, flows):\n",
        "        padded_flows = F.pad(flows, (1, 1, 1, 1), mode='replicate')\n",
        "        height, width = flows.size(2), flows.size(3)\n",
        "        n = float(np.sqrt(height * width))\n",
        "        shifted_flows = [\n",
        "            padded_flows[:, :, 2:, 2:],\n",
        "            padded_flows[:, :, 2:, :-2],\n",
        "            padded_flows[:, :, :-2, 2:],\n",
        "            padded_flows[:, :, :-2, :-2]\n",
        "        ]\n",
        "\n",
        "        diffs = [(flows[:, 1] - shifted_flow[:, 1]) ** 2 + (flows[:, 0] - shifted_flow[:, 0]) ** 2\n",
        "                 for shifted_flow in shifted_flows]\n",
        "        loss = torch.stack(diffs).sum(2, keepdim=True).sum(3, keepdim=True).sum(0, keepdim=True).view(-1)\n",
        "        loss = torch.sqrt(loss)\n",
        "        return loss / n\n",
        "\n",
        "\n",
        "class StadvFlowLoss(nn.Module):\n",
        "\n",
        "    def forward(self,flows, epsilon=1e-8):\n",
        "        padded_flows = F.pad(flows, (1, 1, 1, 1), mode='replicate')\n",
        "        shifted_flows = [\n",
        "            padded_flows[:, :, 2:, 2:],\n",
        "            padded_flows[:, :, 2:, :-2],\n",
        "            padded_flows[:, :, :-2, 2:],\n",
        "            padded_flows[:, :, :-2, :-2]\n",
        "        ]\n",
        "\n",
        "        diffs = [torch.sqrt((flows[:, 1] - shifted_flow[:, 1]) ** 2 +\n",
        "                            (flows[:, 0] - shifted_flow[:, 0]) ** 2 +\n",
        "                            epsilon) for shifted_flow in shifted_flows\n",
        "                 ]\n",
        "        # shape: (4, n, h - 1, w - 1) => (n, )\n",
        "        loss = torch.stack(diffs).sum(2, keepdim=True).sum(3, keepdim=True).sum(0, keepdim=True).view(-1)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class StadvFlow(nn.Module):\n",
        "\n",
        "    def forward(self, images, flows):\n",
        "        batch_size, n_channels, height, width = images.shape\n",
        "        basegrid = torch.stack(torch.meshgrid([torch.arange(height, device=images.device),\n",
        "                                               torch.arange(width, device=images.device)]))\n",
        "        batched_basegrid = basegrid.expand(batch_size, -1, -1, -1)\n",
        "\n",
        "        sampling_grid = batched_basegrid.float() + flows\n",
        "        sampling_grid_x = torch.clamp(sampling_grid[:, 1], 0., float(width) - 1)\n",
        "        sampling_grid_y = torch.clamp(sampling_grid[:, 0], 0., float(height) - 1)\n",
        "\n",
        "        x0 = sampling_grid_x.floor().long()\n",
        "        x1 = x0 + 1\n",
        "        y0 = sampling_grid_y.floor().long()\n",
        "        y1 = y0 + 1\n",
        "\n",
        "        x0.clamp_(0, width - 2)\n",
        "        x1.clamp_(0, width - 1)\n",
        "        y0.clamp_(0, height - 2)\n",
        "        y1.clamp_(0, height - 1)\n",
        "\n",
        "        b = torch.arange(batch_size).view(batch_size, 1, 1).expand(-1, height, width)\n",
        "\n",
        "        Ia = images[b, :, y0, x0].permute(0, 3, 1, 2)\n",
        "        Ib = images[b, :, y1, x0].permute(0, 3, 1, 2)\n",
        "        Ic = images[b, :, y0, x1].permute(0, 3, 1, 2)\n",
        "        Id = images[b, :, y1, x1].permute(0, 3, 1, 2)\n",
        "\n",
        "        x0 = x0.float()\n",
        "        x1 = x1.float()\n",
        "        y0 = y0.float()\n",
        "        y1 = y1.float()\n",
        "\n",
        "        wa = (x1 - sampling_grid_x) * (y1 - sampling_grid_y)\n",
        "        wb = (x1 - sampling_grid_x) * (sampling_grid_y - y0)\n",
        "        wc = (sampling_grid_x - x0) * (y1 - sampling_grid_y)\n",
        "        wd = (sampling_grid_x - x0) * (sampling_grid_y - y0)\n",
        "\n",
        "        wa = wa.unsqueeze(1)\n",
        "        wb = wb.unsqueeze(1)\n",
        "        wc = wc.unsqueeze(1)\n",
        "        wd = wd.unsqueeze(1)\n",
        "\n",
        "        perturbed_image = torch.stack([wa * Ia, wb * Ib, wc * Ic, wd * Id]).sum(0)\n",
        "        return perturbed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k2KNuZNGIsmP"
      },
      "outputs": [],
      "source": [
        "def imagenet_resize_postfn(grad):\n",
        "    grad = grad.abs().max(1, keepdim=True)[0]\n",
        "    grad = F.avg_pool2d(grad, 4).squeeze(1)\n",
        "    shape = grad.shape\n",
        "    grad = grad.view(len(grad), -1)\n",
        "    grad_min = grad.min(1, keepdim=True)[0]\n",
        "    grad = grad - grad_min\n",
        "    grad_max = grad.max(1, keepdim=True)[0]\n",
        "    grad = grad / torch.max(grad_max, torch.tensor([1e-8], device='cuda'))\n",
        "    return grad.view(*shape)\n",
        "\n",
        "\n",
        "def generate_gs_per_batches(model_tup, bx, by, post_fn=None, keep_grad=False):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    bxp = pre_fn(bx)\n",
        "    logit = model(bxp)\n",
        "    loss = F.nll_loss(F.log_softmax(logit), by)\n",
        "    grad = autograd.grad([loss], [bx], create_graph=keep_grad)[0]\n",
        "    if post_fn is not None:\n",
        "        grad = post_fn(grad)\n",
        "    return grad\n",
        "\n",
        "\n",
        "def generate_gs(model_tup, x, y, post_fn=None, keep_grad=False, batch_size=48, device='cuda'):\n",
        "    n = len(x)\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "    generated = []\n",
        "    for i in range(n_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(n, si + batch_size)\n",
        "        bx, by = x[si:ei], y[si:ei]\n",
        "        bx, by = torch.tensor(bx, device=device, requires_grad=True), torch.tensor(by, device='cuda')\n",
        "        generated.append(generate_gs_per_batches(\n",
        "            model_tup, bx, by, post_fn=post_fn,\n",
        "            keep_grad=keep_grad).detach().cpu().numpy())\n",
        "    generated = np.concatenate(generated, axis=0)\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBRC2U9pJKk9"
      },
      "source": [
        "### AdvEdge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XIvg_oYRDiPZ"
      },
      "outputs": [],
      "source": [
        "from contextlib import ExitStack\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class CustomAdam(object):\n",
        "\n",
        "    def __init__(self, lr, beta1=0.9, beta2=0.999, eps=1e-8):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "    def __call__(self, step, params, grads, means, variances, bp_through_optimizer=False):\n",
        "        with torch.no_grad() if not bp_through_optimizer else ExitStack():\n",
        "            new_params = []\n",
        "            new_means = []\n",
        "            new_variances = []\n",
        "            for param, grad, mean, variance in zip(params, grads, means, variances):\n",
        "                # if not bp_through_optimizer:\n",
        "                #     mean = mean.detach()\n",
        "                #     variance = variance.detach()\n",
        "                #     grad = grad.detach()\n",
        "                new_means.append(self.beta1 * mean + (1 - self.beta1) * grad)\n",
        "                new_variances.append(self.beta2 * variance + (1 - self.beta2) * grad * grad)\n",
        "\n",
        "                c_m = new_means[-1] / (1 - self.beta1 ** step)\n",
        "                c_v = new_variances[-1] / (1 - self.beta2 ** step)\n",
        "                new_params.append(param - self.lr / (torch.sqrt(c_v) + self.eps) * c_m)\n",
        "\n",
        "        return new_params, new_means, new_variances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PKDMDR31DQYp"
      },
      "outputs": [],
      "source": [
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MuwrITuhC-pS"
      },
      "outputs": [],
      "source": [
        "def tv_norm(img, beta=2., epsilon=1e-8):\n",
        "    batch_size = img.size(0)\n",
        "    dy = -img[:, :, :-1] + img[:, :, 1:]\n",
        "    dx = (img[:, :, :, 1:] - img[:, :, :, :-1]).transpose(2, 3)\n",
        "    return (dx.pow(2) + dy.pow(2) + epsilon).pow(beta / 2.).reshape(batch_size, -1).sum(1)\n",
        "\n",
        "\n",
        "\n",
        "class GaussianBlur(nn.Module):\n",
        "\n",
        "    def __init__(self, ksize, sigma, num_channels=3):\n",
        "        super(GaussianBlur, self).__init__()\n",
        "        self.ksize = ksize\n",
        "        self.sigma = sigma\n",
        "        self.psize = int((ksize - 1) / 2)\n",
        "        self.num_channels = num_channels\n",
        "        self.blur_kernel = nn.Parameter(get_gaussian_blur_kernel(ksize, sigma).repeat(num_channels, 1, 1, 1),\n",
        "                                        requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_padded = F.pad(x, [self.psize] * 4, mode=\"reflect\")\n",
        "        return F.conv2d(x_padded, self.blur_kernel, groups=self.num_channels)\n",
        "\n",
        "\n",
        "class MASK(object):\n",
        "\n",
        "    def __init__(self, cuda):\n",
        "        self.gaussian_blur = GaussianBlur(11, 10)\n",
        "        if cuda:\n",
        "            self.gaussian_blur.cuda()\n",
        "\n",
        "\n",
        "def mask_iter(mask_model, model, pre_fn, x, y, r, m_init, l1_lambda=1e-2, tv_lambda=1e-4, tv_beta=3., noise_std=0.,\n",
        "              weights=None, x_blurred=None):\n",
        "    batch_size = x.size(0)\n",
        "    cuda = x.is_cuda\n",
        "    if r is not None:\n",
        "        x = x + r\n",
        "    if x_blurred is None:\n",
        "        x_blurred = mask_model.gaussian_blur(x)\n",
        "    m = F.upsample(m_init, size=(x.size(2), x.size(3)), mode=\"bilinear\")\n",
        "    perturbed_inputs = m * x + (1. - m) * x_blurred\n",
        "    if noise_std != 0:\n",
        "        noise = noise_std * torch.randn(*perturbed_inputs.size())\n",
        "        if cuda:\n",
        "            noise = noise.cuda()\n",
        "        perturbed_inputs = perturbed_inputs + noise\n",
        "\n",
        "    outputs = F.softmax(model(pre_fn(perturbed_inputs)), 1)\n",
        "    l1_loss = torch.mean(torch.abs(1 - m_init).view(batch_size, -1), 1)\n",
        "    tv_loss = tv_norm(m_init, tv_beta)\n",
        "    class_loss = outputs.gather(1, y[:, None])[:, 0]\n",
        "    if weights is None:\n",
        "        tot_loss = l1_lambda * torch.sum(l1_loss) + tv_lambda * torch.sum(tv_loss) + torch.sum(class_loss)\n",
        "    else:\n",
        "        tot_loss = (l1_lambda * torch.sum(l1_loss * weights) + tv_lambda * torch.sum(tv_loss * weights) +\n",
        "                    torch.sum(class_loss * weights))\n",
        "    return tot_loss, [l1_loss, tv_lambda, class_loss]\n",
        "\n",
        "\n",
        "class MASKV2(object):\n",
        "\n",
        "    def __init__(self, cuda):\n",
        "        self.blur1 = GaussianBlur(21, -1)\n",
        "        self.blur2 = GaussianBlur(11, -1, 1)\n",
        "        self.cuda = cuda\n",
        "        if cuda:\n",
        "            self.blur1.cuda()\n",
        "            self.blur2.cuda()\n",
        "\n",
        "\n",
        "def mask_iter_v2(mask_model, model, pre_fn, x, y, m_init, l1_lambda=1e-4, tv_lambda=1e-2, tv_beta=3., noise_std=0.,\n",
        "                 jitter=4, weights=None, x_blurred=None):\n",
        "    batch_size = x.size(0)\n",
        "    if x_blurred is None:\n",
        "        x_blurred = mask_model.blur1(x)\n",
        "\n",
        "    if jitter != 0:\n",
        "        j1 = np.random.randint(jitter)\n",
        "        j2 = np.random.randint(jitter)\n",
        "    else:\n",
        "        j1, j2 = 0, 0\n",
        "    x_ = x[:, :, j1:j1+224, j2:j2+224]\n",
        "    x_blurred_ = x_blurred[:, :, j1:j1+224, j2:j2+224]\n",
        "\n",
        "    if noise_std != 0:\n",
        "        noisy = torch.randn_like(m_init)\n",
        "        mask_w_noisy = m_init + noisy\n",
        "        mask_w_noisy.clamp_(0, 1)\n",
        "    else:\n",
        "        mask_w_noisy = m_init\n",
        "\n",
        "    mask_w_noisy = F.interpolate(mask_w_noisy, (224, 224), mode='bilinear')\n",
        "    mask_w_noisy = mask_model.blur2(mask_w_noisy)\n",
        "    x = x_ * mask_w_noisy + x_blurred_ * (1 - mask_w_noisy)\n",
        "\n",
        "    class_loss = F.softmax(model(pre_fn(x)), dim=-1).gather(1, y.unsqueeze(1)).squeeze(1)\n",
        "    l1_loss = (1 - m_init).abs().view(batch_size, -1).sum(-1)\n",
        "    tv_loss = tv_norm(m_init, tv_beta)\n",
        "\n",
        "    if weights is None:\n",
        "        tot_loss = l1_lambda * torch.sum(l1_loss) + tv_lambda * torch.sum(tv_loss) + torch.sum(class_loss)\n",
        "    else:\n",
        "        tot_loss = (l1_lambda * torch.sum(l1_loss * weights) + tv_lambda * torch.sum(tv_loss * weights) +\n",
        "                    torch.sum(class_loss * weights))\n",
        "    return tot_loss, [l1_loss, tv_lambda, class_loss]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qOEptZF7DdzB"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "def get_default_mask_config():\n",
        "    return dict(lr=0.1, l1_lambda=1e-2, tv_lambda=1e-4, noise_std=0, n_iters=400,\n",
        "                batch_size=40, verbose=False)\n",
        "\n",
        "\n",
        "def generate_mask_per_batch(mask_config, mask_model, model_tup, batch_tup, cuda, m_init=None):\n",
        "    bx, by = batch_tup\n",
        "    batch_size = len(bx)\n",
        "    if not isinstance(bx, torch.Tensor):\n",
        "        bx = torch.tensor(bx)\n",
        "    if not isinstance(by, torch.Tensor):\n",
        "        by = torch.tensor(by)\n",
        "    model, pre_fn, shape = model_tup\n",
        "    if m_init is None:\n",
        "        m_init = torch.zeros(batch_size, 1, 28, 28).fill_(0.5)\n",
        "    else:\n",
        "        m_init = m_init.detach()\n",
        "    if cuda:\n",
        "        bx, by = bx.cuda(), by.cuda()\n",
        "        m_init = m_init.cuda()\n",
        "    m_init.requires_grad = True\n",
        "    optimizer = Adam([m_init], lr=mask_config['lr'])\n",
        "    bx_blurred = mask_model.gaussian_blur(bx)\n",
        "    for i in range(mask_config['n_iters']):\n",
        "        tot_loss = mask_iter(mask_model, model, pre_fn, bx, by, None,\n",
        "                             m_init, mask_config['l1_lambda'], mask_config['tv_lambda'],\n",
        "                             noise_std=mask_config['noise_std'], x_blurred=bx_blurred)[0]\n",
        "        if mask_config['verbose'] and i % 50 == 0:\n",
        "            print(i, np.asscalar(tot_loss) / batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        tot_loss.backward()\n",
        "        optimizer.step()\n",
        "        m_init.data.clamp_(0, 1)\n",
        "    return m_init\n",
        "\n",
        "\n",
        "def generate_masks(mask_config, model_tup, images_tup, cuda):\n",
        "    if mask_config is None:\n",
        "        mask_config = get_default_mask_config()\n",
        "    mask_model = MASK(cuda)\n",
        "    img_x, img_y = images_tup[:2]\n",
        "    batch_size = mask_config['batch_size']\n",
        "    num_batches = (len(img_x) + batch_size - 1) // batch_size\n",
        "\n",
        "    masks = []\n",
        "    for i in range(num_batches):\n",
        "        start_index = i * batch_size\n",
        "        end_index = min(len(img_x), start_index + batch_size)\n",
        "        bx, by = img_x[start_index:end_index], img_y[start_index:end_index]\n",
        "        masks.append(generate_mask_per_batch(mask_config, mask_model, model_tup, (bx, by), cuda).detach().cpu().numpy())\n",
        "\n",
        "    return np.concatenate(masks, axis=0)\n",
        "\n",
        "\n",
        "def generate_mask_per_batch_v2(mask_config, mask_model, model_tup, batch_tup, cuda, m_init=None):\n",
        "    bx, by = batch_tup\n",
        "    batch_size = len(bx)\n",
        "    if not isinstance(bx, torch.Tensor):\n",
        "        bx = torch.tensor(bx)\n",
        "    if not isinstance(by, torch.Tensor):\n",
        "        by = torch.tensor(by)\n",
        "    model, pre_fn, shape = model_tup\n",
        "    if m_init is None:\n",
        "        m_init = torch.zeros(batch_size, 1, 28, 28).fill_(0.5)\n",
        "    else:\n",
        "        m_init = m_init.clone().detach()\n",
        "    if cuda:\n",
        "        bx, by = bx.cuda(), by.cuda()\n",
        "        m_init = m_init.cuda()\n",
        "    m_init.requires_grad = True\n",
        "    optimizer = Adam([m_init], lr=mask_config['lr'])\n",
        "    bx = F.interpolate(bx, (224 + 4, 224 + 4), mode='bilinear')\n",
        "    bx_blurred = mask_model.blur1(bx)\n",
        "    for i in range(mask_config['n_iters']):\n",
        "        tot_loss = mask_iter_v2(mask_model, model, pre_fn, bx, by,\n",
        "                                m_init, mask_config['l1_lambda'], mask_config['tv_lambda'],\n",
        "                                noise_std=mask_config['noise_std'], x_blurred=bx_blurred)[0]\n",
        "        if mask_config['verbose'] and i % 50 == 0:\n",
        "            print(i, np.asscalar(tot_loss) / batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        tot_loss.backward()\n",
        "        optimizer.step()\n",
        "        m_init.data.clamp_(0, 1)\n",
        "    return m_init\n",
        "\n",
        "\n",
        "def generate_masks_v2(mask_config, model_tup, images_tup, cuda):\n",
        "    if mask_config is None:\n",
        "        mask_config = get_default_mask_config()\n",
        "    mask_model = MASKV2(cuda)\n",
        "    img_x, img_y = images_tup[:2]\n",
        "    batch_size = mask_config['batch_size']\n",
        "    num_batches = (len(img_x) + batch_size - 1) // batch_size\n",
        "\n",
        "    masks = []\n",
        "    for i in range(num_batches):\n",
        "        start_index = i * batch_size\n",
        "        end_index = min(len(img_x), start_index + batch_size)\n",
        "        bx, by = img_x[start_index:end_index], img_y[start_index:end_index]\n",
        "        masks.append(generate_mask_per_batch_v2(mask_config, mask_model, model_tup, (bx, by), cuda).detach().cpu().numpy())\n",
        "\n",
        "    return np.concatenate(masks, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0hGFu5qzO_zg"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam as TorchAdam\n",
        "\n",
        "PGD_SAVE_PERIOD = 50\n",
        "\n",
        "def load_model(config):\n",
        "    pre_fn = imagenet_normalize\n",
        "    if config['model'] == 'resnet50':\n",
        "        model = resnet50(pretrained=True)\n",
        "        shape = (224, 224)\n",
        "    if config['model'] == 'densenet169':\n",
        "        model = densenet169(pretrained=True)\n",
        "        shape = (224, 224)\n",
        "    freeze_model(model)\n",
        "    model.train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model.cuda()\n",
        "    return model, pre_fn, shape\n",
        "\n",
        "def attack_batch(config, model_tup, mask_model, batch_tup, m0):\n",
        "    device = 'cuda' if config['device'] == 'gpu' else 'cpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    m0_np = m0\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by, m0 = (torch.tensor(bx_np, device=device), torch.tensor(by_np, device=device),\n",
        "              torch.tensor(m0, device=device))\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    dobj = {}\n",
        "\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    m = torch.empty_like(m0).fill_(0.5)\n",
        "    m.requires_grad = True\n",
        "\n",
        "    images = bx\n",
        "    flows = 0.2 * (torch.rand(batch_size, 2, images.size(2), images.size(3), device=device) - 0.5)\n",
        "    flows.requires_grad_(True)\n",
        "\n",
        "    tau = config['tau']\n",
        "    flow_obj = StadvFlow()\n",
        "    flow_loss_obj = StadvFlowLoss()\n",
        "    flow_tvloss_obj = StadvTVLoss()\n",
        "    optimizer = TorchAdam([flows], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = flow_obj(images, flows)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + pert\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "        adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "        total_loss = adv_loss + tau * flow_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0 or i == config['s1_iters'] - 1:\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_tvloss_obj(flows)\n",
        "                preds = logits.argmax(1)\n",
        "                succeed = (preds == by).float().mean().item()\n",
        "            print('s1-step: %d, average adv loss: %.4f, average flow loss: %.4f, succeed: %.2f' %\n",
        "                  (i, adv_loss.mean().item(), flow_loss.mean().item(), succeed))\n",
        "\n",
        "    optimizer = CustomAdam(0.01)\n",
        "    torch_optimizer = TorchAdam([flows], lr=0.005, amsgrad=True)\n",
        "\n",
        "    mean_his = [torch.zeros_like(m0)]\n",
        "    variance_his = [torch.zeros_like(m0)]\n",
        "    no_backprop_steps = 4\n",
        "    backprop_steps = 4\n",
        "    adam_step = 0\n",
        "    attack_mask_config = dict(lr=0.1, l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'],\n",
        "                              noise_std=0, n_iters=config['mask_iter'],\n",
        "                              verbose=False)\n",
        "\n",
        "    best_l2_dists = np.full(len(bx), 1e10, dtype=np.float32)\n",
        "    best_adv_x = np.zeros_like(bx_np)\n",
        "    best_adv_mask = np.zeros_like(m0_np)\n",
        "\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "        if i % PGD_SAVE_PERIOD == PGD_SAVE_PERIOD - 1:\n",
        "            with torch.no_grad():\n",
        "                adv_images = flow_obj(images, flows)\n",
        "            mask_now_disc = generate_mask_per_batch_v2(attack_mask_config, mask_model, model_tup,\n",
        "                                                       batch_tup=(adv_images_, by),\n",
        "                                                       cuda=config['device'] == 'gpu').detach_()\n",
        "\n",
        "            bx_adv_disc_np = np.uint8(255 * adv_images_.cpu().numpy())\n",
        "            bx_adv_disc = torch.tensor(np.float32(bx_adv_disc_np / 255.))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits_disc = model(pre_fn(adv_images_))\n",
        "\n",
        "            succeed = (logits_disc.argmax(1) == by).long().cpu().numpy()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                diff = m0 - mask_now_disc\n",
        "                diff_norm = diff.view(batch_size, -1).norm(2, 1).cpu().numpy()\n",
        "\n",
        "            update_flag = np.logical_and(diff_norm < best_l2_dists, succeed.astype(np.bool))\n",
        "            bx_adv_disc_np = bx_adv_disc.cpu().numpy()\n",
        "            mask_now_disc_np = mask_now_disc.cpu().numpy()\n",
        "            best_adv_x[update_flag] = bx_adv_disc_np[update_flag]\n",
        "            best_l2_dists[update_flag] = diff_norm[update_flag]\n",
        "            best_adv_mask[update_flag] = mask_now_disc_np[update_flag]\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_loss_obj(flows, 0.)\n",
        "                flow_tvloss = flow_tvloss_obj(flows)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                diff = m0 - mask_now_disc\n",
        "                diff = np.asscalar((diff * diff).sum())\n",
        "                flow_tvloss = flow_tvloss_obj(flows).mean().item()\n",
        "                adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "                adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "\n",
        "            print('step', i, 'l2 dist now', diff, 'succeed', np.asscalar((logits_disc.argmax(1) == by).float().mean()),\n",
        "                  'succeed_disc', np.asscalar((logits_disc.argmax(1) == by).float().mean()),\n",
        "                  'flow tvloss', flow_tvloss, 'adv loss', adv_loss.mean().item())\n",
        "            m.data = mask_now_disc.data\n",
        "            mean_his = [0.5 * mean_his[0]] # mean_his[0].detach()]\n",
        "            variance_his = [0.25 * variance_his[0]]\n",
        "            adam_step = 100\n",
        "\n",
        "        for j in range(no_backprop_steps):\n",
        "            adv_images_ = adv_images.detach()\n",
        "            int_loss = mask_iter_v2(mask_model, model, pre_fn,\n",
        "                                    F.interpolate(adv_images_, (228, 228), mode='bilinear'),\n",
        "                                    by, m, noise_std=0,\n",
        "                                    l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'])[0]\n",
        "            int_grad = autograd.grad([int_loss], [m])[0]\n",
        "            objs = optimizer.__call__(adam_step + 1, [m], [int_grad], mean_his, variance_his, False)\n",
        "            m = objs[0][0]\n",
        "            m = torch.clamp(m, 0, 1)\n",
        "            mean_his = objs[-2]\n",
        "            variance_his = objs[-1]\n",
        "            m = m.detach()\n",
        "            m.requires_grad = True\n",
        "            adam_step += 1\n",
        "\n",
        "        diffs = []\n",
        "        for j in range(backprop_steps):\n",
        "            adv_images = flow_obj(images, flows)\n",
        "            int_loss = mask_iter_v2(mask_model, model, pre_fn,\n",
        "                                    F.interpolate(adv_images, (228, 228), mode='bilinear'),\n",
        "                                    by, m, noise_std=0,\n",
        "                                    l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'])[0]\n",
        "            int_grad = autograd.grad([int_loss], [m], create_graph=True)[0]\n",
        "            objs = optimizer.__call__(adam_step + 1, [m], [int_grad], mean_his, variance_his, True)\n",
        "            m = objs[0][0]\n",
        "            m = torch.clamp(m, 0, 1)\n",
        "            mean_his = objs[-2]\n",
        "            variance_his = objs[-1]\n",
        "            diff = m - m0\n",
        "            diffs.append((diff * diff).sum())\n",
        "            m = m.detach()\n",
        "            m.requires_grad = True\n",
        "            adam_step += 1\n",
        "\n",
        "        int_final_loss = torch.stack(diffs).mean()\n",
        "        adv_images = flow_obj(images, flows)\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "        adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "        total_loss = 500 * int_final_loss + adv_loss.sum() + 0.004 * flow_loss_obj(flows).sum()\n",
        "\n",
        "        torch_optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        torch_optimizer.step()\n",
        "\n",
        "    dobj['adv_x'] = best_adv_x\n",
        "    dobj['adv_mask'] = best_adv_mask\n",
        "    dobj['adv_succeed'] = (best_l2_dists < 1e6).astype(np.int64)\n",
        "    dobj['tmask'] = m0_np\n",
        "\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_y, img_yt = (data_arx['img_x'].copy(), data_arx['img_y'].copy(),\n",
        "                            data_arx['img_yt'].copy())\n",
        "    mask_benign = data_arx['mask_benign_y'].copy()\n",
        "    mask_model = MASKV2(config['device'] == 'gpu')\n",
        "    model_tup = load_model(config)\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], mask_benign[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, mask_model, (bx, byt), bm0)\n",
        "\n",
        "        save_dobjs.append(dobj)\n",
        "        print('done batch: %d' % i)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "    save_dobj.update(dict(img_x=img_x, img_y=img_y, img_yt=img_yt, mask_benign_y=mask_benign))\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    np.savez(config['save_path'], **save_dobj)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pkQ0OVChG90R"
      },
      "outputs": [],
      "source": [
        "def attack_mask(data_path, fName):\n",
        "    config = {}\n",
        "\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['model'] = 'densenet169'\n",
        "    config['batch_size'] = 5\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 400\n",
        "    config['s1_lr'] = 1. / 255\n",
        "    config['s2_iters'] = 1000\n",
        "    config['s2_beta'] = 0.05\n",
        "    config['mask_iter'] = 300\n",
        "    config['mask_noise_std'] = 0\n",
        "    config['mask_tv_lambda'] = 1e-2\n",
        "    config['mask_l1_lambda'] = 1e-4\n",
        "    config['tau'] = 0.0005\n",
        "    config['c'] = 5.\n",
        "\n",
        "    # if(not os.path.exists(save_path)):\n",
        "    #   os.mkdir(save_path)\n",
        "\n",
        "    attack(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "NdjUXpcEKcWI",
        "outputId": "8043a466-5720-4af2-f728-cefe9469ddaa",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-1ff4cffe0222>:523: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
            "100%|██████████| 54.7M/54.7M [00:00<00:00, 96.4MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1-step: 0, average adv loss: 16.1598, average flow loss: 0.1981, succeed: 0.00\n",
            "s1-step: 50, average adv loss: 6.5109, average flow loss: 0.1714, succeed: 0.20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e10800fb4870>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattack_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-be1a5a246769>\u001b[0m in \u001b[0;36mattack_mask\u001b[0;34m(data_path, fName)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#   os.mkdir(save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-493e92542627>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_yt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_benign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mdobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0msave_dobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-493e92542627>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(config, model_tup, mask_model, batch_tup, m0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1_iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mpert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madv_images\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f013a879f5b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, flows)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mIa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mIb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mIc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "attack_mask('mask.npz', 'output_1.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge+"
      ],
      "metadata": {
        "id": "yKHaMBlFQs-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KukZJpv6CPoK"
      },
      "outputs": [],
      "source": [
        "def attack_batch(config, model_tup, mask_model, batch_tup, m0):\n",
        "    device = 'cuda' if config['device'] == 'gpu' else 'cpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    m0_np = m0\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by, m0 = (torch.tensor(bx_np, device=device), torch.tensor(by_np, device=device),\n",
        "              torch.tensor(m0, device=device))\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    dobj = {}\n",
        "\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    m = torch.empty_like(m0).fill_(0.5)\n",
        "    m.requires_grad = True\n",
        "\n",
        "\n",
        "    images = bx\n",
        "    flows = 0.2 * (torch.rand(batch_size, 2, images.size(2), images.size(3), device=device) - 0.5)\n",
        "    flows.requires_grad_(True)\n",
        "\n",
        "    tau = config['tau']\n",
        "    flow_obj = StadvFlow()\n",
        "    flow_loss_obj = StadvFlowLoss()\n",
        "    flow_tvloss_obj = StadvTVLoss()\n",
        "    optimizer = TorchAdam([flows], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        adv_images = flow_obj(images, flows)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + torch.where(weights > 0.1, pert, torch.tensor(0.).to(device))\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "        adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "        flow_loss = flow_loss_obj(flows)\n",
        "        total_loss = adv_loss + tau * flow_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0 or i == config['s1_iters'] - 1:\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_tvloss_obj(flows)\n",
        "                preds = logits.argmax(1)\n",
        "                succeed = (preds == by).float().mean().item()\n",
        "            print('s1-step: %d, average adv loss: %.4f, average flow loss: %.4f, succeed: %.2f' %\n",
        "                  (i, adv_loss.mean().item(), flow_loss.mean().item(), succeed))\n",
        "\n",
        "    optimizer = CustomAdam(0.01)\n",
        "    torch_optimizer = TorchAdam([flows], lr=0.005, amsgrad=True)\n",
        "\n",
        "    mean_his = [torch.zeros_like(m0)]\n",
        "    variance_his = [torch.zeros_like(m0)]\n",
        "    no_backprop_steps = 4\n",
        "    backprop_steps = 4\n",
        "    adam_step = 0\n",
        "    attack_mask_config = dict(lr=0.1, l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'],\n",
        "                              noise_std=0, n_iters=config['mask_iter'],\n",
        "                              verbose=False)\n",
        "\n",
        "    best_l2_dists = np.full(len(bx), 1e10, dtype=np.float32)\n",
        "    best_adv_x = np.zeros_like(bx_np)\n",
        "    best_adv_mask = np.zeros_like(m0_np)\n",
        "\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "        if i % PGD_SAVE_PERIOD == PGD_SAVE_PERIOD - 1:\n",
        "            with torch.no_grad():\n",
        "                adv_images = flow_obj(images, flows)\n",
        "            mask_now_disc = generate_mask_per_batch_v2(attack_mask_config, mask_model, model_tup,\n",
        "                                                       batch_tup=(adv_images_, by),\n",
        "                                                       cuda=config['device'] == 'gpu').detach_()\n",
        "\n",
        "            bx_adv_disc_np = np.uint8(255 * adv_images_.cpu().numpy())\n",
        "            bx_adv_disc = torch.tensor(np.float32(bx_adv_disc_np / 255.))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits_disc = model(pre_fn(adv_images_))\n",
        "\n",
        "            succeed = (logits_disc.argmax(1) == by).long().cpu().numpy()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                diff = m0 - mask_now_disc\n",
        "                diff_norm = diff.view(batch_size, -1).norm(2, 1).cpu().numpy()\n",
        "\n",
        "            update_flag = np.logical_and(diff_norm < best_l2_dists, succeed.astype(np.bool))\n",
        "            bx_adv_disc_np = bx_adv_disc.cpu().numpy()\n",
        "            mask_now_disc_np = mask_now_disc.cpu().numpy()\n",
        "            best_adv_x[update_flag] = bx_adv_disc_np[update_flag]\n",
        "            best_l2_dists[update_flag] = diff_norm[update_flag]\n",
        "            best_adv_mask[update_flag] = mask_now_disc_np[update_flag]\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                flow_loss = flow_loss_obj(flows, 0.)\n",
        "                flow_tvloss = flow_tvloss_obj(flows)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                diff = m0 - mask_now_disc\n",
        "                diff = np.asscalar((diff * diff).sum())\n",
        "                flow_tvloss = flow_tvloss_obj(flows).mean().item()\n",
        "                adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "                adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "\n",
        "            print('step', i, 'l2 dist now', diff, 'succeed', np.asscalar((logits_disc.argmax(1) == by).float().mean()),\n",
        "                  'succeed_disc', np.asscalar((logits_disc.argmax(1) == by).float().mean()),\n",
        "                  'flow tvloss', flow_tvloss, 'adv loss', adv_loss.mean().item())\n",
        "            m.data = mask_now_disc.data\n",
        "            mean_his = [0.5 * mean_his[0]] # mean_his[0].detach()]\n",
        "            variance_his = [0.25 * variance_his[0]]\n",
        "            adam_step = 100\n",
        "\n",
        "        for j in range(no_backprop_steps):\n",
        "            adv_images_ = adv_images.detach()\n",
        "            int_loss = mask_iter_v2(mask_model, model, pre_fn,\n",
        "                                    F.interpolate(adv_images_, (228, 228), mode='bilinear'),\n",
        "                                    by, m, noise_std=0,\n",
        "                                    l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'])[0]\n",
        "            int_grad = autograd.grad([int_loss], [m])[0]\n",
        "            objs = optimizer.__call__(adam_step + 1, [m], [int_grad], mean_his, variance_his, False)\n",
        "            m = objs[0][0]\n",
        "            m = torch.clamp(m, 0, 1)\n",
        "            mean_his = objs[-2]\n",
        "            variance_his = objs[-1]\n",
        "            m = m.detach()\n",
        "            m.requires_grad = True\n",
        "            adam_step += 1\n",
        "\n",
        "        diffs = []\n",
        "        for j in range(backprop_steps):\n",
        "            adv_images = flow_obj(images, flows)\n",
        "            int_loss = mask_iter_v2(mask_model, model, pre_fn,\n",
        "                                    F.interpolate(adv_images, (228, 228), mode='bilinear'),\n",
        "                                    by, m, noise_std=0,\n",
        "                                    l1_lambda=config['mask_l1_lambda'], tv_lambda=config['mask_tv_lambda'])[0]\n",
        "            int_grad = autograd.grad([int_loss], [m], create_graph=True)[0]\n",
        "            objs = optimizer.__call__(adam_step + 1, [m], [int_grad], mean_his, variance_his, True)\n",
        "            m = objs[0][0]\n",
        "            m = torch.clamp(m, 0, 1)\n",
        "            mean_his = objs[-2]\n",
        "            variance_his = objs[-1]\n",
        "            diff = m - m0\n",
        "            diffs.append((diff * diff).sum())\n",
        "            m = m.detach()\n",
        "            m.requires_grad = True\n",
        "            adam_step += 1\n",
        "\n",
        "        int_final_loss = torch.stack(diffs).mean()\n",
        "        adv_images = flow_obj(images, flows)\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        adv_loss = logits.scatter(1, by[:, None], -100000).max(1)[0] - logits.gather(1, by[:, None])[:, 0]\n",
        "        adv_loss = torch.max(adv_loss, torch.full_like(adv_loss, -5.))\n",
        "        total_loss = 500 * int_final_loss + adv_loss.sum() + 0.004 * flow_loss_obj(flows).sum()\n",
        "\n",
        "        torch_optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        torch_optimizer.step()\n",
        "\n",
        "    dobj['adv_x'] = best_adv_x\n",
        "    dobj['adv_mask'] = best_adv_mask\n",
        "    dobj['adv_succeed'] = (best_l2_dists < 1e6).astype(np.int64)\n",
        "    dobj['tmask'] = m0_np\n",
        "\n",
        "    return dobj\n",
        "\n",
        "\n",
        "def attack(config):\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_y, img_yt = (data_arx['img_x'].copy(), data_arx['img_y'].copy(),\n",
        "                            data_arx['img_yt'].copy())\n",
        "    mask_benign = data_arx['mask_benign_y'].copy()\n",
        "    mask_model = MASKV2(config['device'] == 'gpu')\n",
        "    model_tup = load_model(config)\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], mask_benign[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, mask_model, (bx, byt), bm0)\n",
        "\n",
        "        save_dobjs.append(dobj)\n",
        "        print('done batch: %d' % i)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "    save_dobj.update(dict(img_x=img_x, img_y=img_y, img_yt=img_yt, mask_benign_y=mask_benign))\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    np.savez(config['save_path'], **save_dobj)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attack_mask_2(data_path, fName):\n",
        "    config = {}\n",
        "\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['model'] = 'resnet50'\n",
        "    config['batch_size'] = 5\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 400\n",
        "    config['s1_lr'] = 1. / 255\n",
        "    config['s2_iters'] = 1000\n",
        "    config['s2_beta'] = 0.05\n",
        "    config['mask_iter'] = 300\n",
        "    config['mask_noise_std'] = 0\n",
        "    config['mask_tv_lambda'] = 1e-2\n",
        "    config['mask_l1_lambda'] = 1e-4\n",
        "    config['tau'] = 0.0005\n",
        "    config['c'] = 5.\n",
        "\n",
        "    # if(not os.path.exists(save_path)):\n",
        "    #   os.mkdir(save_path)\n",
        "\n",
        "    attack(config)"
      ],
      "metadata": {
        "id": "yf5zL778Q6Bx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_mask_2('mask.npz', 'output_1.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "9IlSk-28Q9af",
        "outputId": "4f38b254-dc3c-4bf8-dfeb-1e9238b9ffb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 347MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1-step: 0, average adv loss: 13.2232, average flow loss: 0.1975, succeed: 0.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6c90920ec283>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattack_mask_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-fd96d0608c74>\u001b[0m in \u001b[0;36mattack_mask_2\u001b[0;34m(data_path, fName)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#   os.mkdir(save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-8859bd7eff49>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_yt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_benign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mdobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0msave_dobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8859bd7eff49>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(config, model_tup, mask_model, batch_tup, m0)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1_iters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyCkdaSFRAgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}