{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gCrLQmlZr4aZ"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "import time\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y2qYTfFSG3l8"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.set_device(1)\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "blQI-HOSsIwQ"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F_XzbBgeuCqm"
      },
      "outputs": [],
      "source": [
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E8CZINPCtAtu"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pt0yZWBasNMe"
      },
      "outputs": [],
      "source": [
        "def cam_resnet50_forward(model_tup, x):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    res = model(pre_fn(x), out_keys=[\"l4\", \"gvp\", \"fc\"])\n",
        "    return res['l4'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "def cam_resnet50_fc_weight(model_tup):\n",
        "    model = model_tup[0]\n",
        "    return model.fc.weight\n",
        "\n",
        "\n",
        "def cam_resnet50():\n",
        "    model = resnet50(pretrained=True)\n",
        "    model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "    return model_tup, (cam_resnet50_forward, cam_resnet50_fc_weight)\n",
        "\n",
        "\n",
        "def cam_densenet169_forward(model_tup, x):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    res = model(pre_fn(x), out_keys=['l', 'gvp', 'fc'])\n",
        "    return res['l'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "def cam_densenet169_fc_weight(model_tup):\n",
        "    model = model_tup[0]\n",
        "    return model.classifier.weight\n",
        "\n",
        "\n",
        "def cam_densenet169():\n",
        "    model = densenet169(pretrained=True)\n",
        "    model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "    return model_tup, (cam_densenet169_forward, cam_densenet169_fc_weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KTs2c6m0tF8-"
      },
      "outputs": [],
      "source": [
        "class CAM(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, model_tup, forward_tup, x, y=None):\n",
        "        return cam_forward(model_tup, forward_tup, x, y)\n",
        "\n",
        "\n",
        "def cam_forward(model_tup, forward_tup, x, y):\n",
        "    forward_fn, fc_weight_fn = forward_tup\n",
        "    batch_size = x.size(0)\n",
        "    cuda = x.is_cuda\n",
        "    if y is None:\n",
        "        with torch.no_grad():\n",
        "            logits = forward_fn(model_tup, x)[-1]\n",
        "            logits = logits.cpu().numpy()[0]\n",
        "        true_label = int(np.argmax(logits))\n",
        "        y = torch.tensor([true_label])\n",
        "        if cuda:\n",
        "            y = y.cuda()\n",
        "\n",
        "    vs, gs, logits = forward_fn(model_tup, x)\n",
        "    wc = fc_weight_fn(model_tup)[y].view(batch_size, -1, 1, 1)\n",
        "    prod = (wc * vs).sum(1, keepdim=True)\n",
        "\n",
        "    return logits, prod\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6lzkxwl3JfD"
      },
      "source": [
        "C&W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-HI2s8h5mPc"
      },
      "source": [
        "### AdvEdge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ERlKOT3r2CTy"
      },
      "outputs": [],
      "source": [
        "PGD_SAVE_PERIOD = 50\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "def load_model(config):\n",
        "    if config['model'] == 'resnet50':\n",
        "        model_tup, forward_tup = cam_resnet50()\n",
        "    if config['model'] == 'densenet169':\n",
        "        model_tup, forward_tup = cam_densenet169()\n",
        "    model = model_tup[0]\n",
        "    freeze_model(model)\n",
        "    model.train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model.cuda()\n",
        "    return model_tup, forward_tup\n",
        "\n",
        "def tanh_space(x):\n",
        "    return 1/2*(torch.tanh(x) + 1)\n",
        "\n",
        "def inverse_tanh_space(x):\n",
        "    return atanh(x*2-1)\n",
        "\n",
        "def atanh(x):\n",
        "    return 0.5*torch.log((1+x)/(1-x))\n",
        "\n",
        "def f(outputs, labels, kappa):\n",
        "\n",
        "    one_hot_labels = torch.eye(len(outputs[0]))[labels.cpu()].cuda()\n",
        "    i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
        "    j = torch.masked_select(outputs, one_hot_labels.bool())\n",
        "\n",
        "    # if self._targeted:\n",
        "    return torch.clamp((i-j), min=-kappa)\n",
        "    # else:\n",
        "    #     return torch.clamp((j-i), min=-self.kappa)\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(cam_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    w = inverse_tanh_space(bx.clone().detach()).detach()\n",
        "    w.requires_grad_()\n",
        "\n",
        "    best_adv_images = bx.clone().detach()\n",
        "    best_L2 = 1e10*torch.ones((len(bx))).to('cuda')\n",
        "    prev_cost = 1e10\n",
        "    dim = len(bx.shape)\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "    dobj = {}\n",
        "\n",
        "    MSELoss = nn.MSELoss(reduction='none')\n",
        "    Flatten = nn.Flatten()\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + pert\n",
        "\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        f_loss = f(logits, by, config['kappa']).sum()\n",
        "\n",
        "        cost = L2_loss + 1e-4*f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "        c_now += c_inc\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "\n",
        "        # adv_images = flow_obj(images, flows)\n",
        "        # flow_loss = flow_loss_obj(flows)\n",
        "\n",
        "        logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = (diff * diff).mean(1)\n",
        "        total_loss = 2 * adv_loss + L2_loss + c_now * loss_cam\n",
        "\n",
        "        # record examples\n",
        "        # if i % PGD_SAVE_PERIOD == PGD_SAVE_PERIOD - 1:\n",
        "        #     cam_flatten_n = cam_flatten.view(*cam.size()).detach()\n",
        "        #     dobj[adv_step_template % (i + 1)] = adv_images.detach().cpu().numpy()\n",
        "        #     dobj[cam_step_template % (i + 1)] = cam.detach().cpu().numpy()\n",
        "        #     dobj[cam_n_step_template % (i + 1)] = cam_flatten_n.cpu().numpy()\n",
        "        #     dobj[logits_step_template % (i + 1)] = logits.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, pre = torch.max(logits.detach(), 1)\n",
        "        correct = (pre == by).float()\n",
        "\n",
        "        mask = (1-correct)*(best_L2 > current_L2.detach())\n",
        "        best_L2 = mask*current_L2.detach() + (1-mask)*best_L2\n",
        "\n",
        "        mask = mask.view([-1]+[1]*(dim-1))\n",
        "        best_adv_images = mask*adv_images.detach() + (1-mask)*best_adv_images\n",
        "\n",
        "        if i % 50 == 49:\n",
        "            cam_flatten_n = cam_flatten.view(*cam.size()).detach()\n",
        "            dobj['adv_x'] = best_adv_images.detach().cpu().numpy()\n",
        "            dobj['adv_cam'] = cam_flatten_n.detach().cpu().numpy()\n",
        "            dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "            dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "            dobj['tcam'] = cam_benign\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = loss_cam.mean().item()\n",
        "                loss_adv_mu = adv_loss.mean().item()\n",
        "                # flow_loss = flow_tvloss_obj(flows).mean().item()\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                adv_loss = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss cam: %.5f, succeed: %d' %\n",
        "                  (i, adv_loss, loss_cam, num_succeed))\n",
        "\n",
        "    return dobj\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['model'] = 'resnet50'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 1500\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "    config['kappa'] = 0\n",
        "    config['tau'] = 0.0005\n",
        "\n",
        "    # if(not os.path.exists('cam_attack_output/')):\n",
        "    #   os.mkdir('cam_attack_output')\n",
        "\n",
        "    attack(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCxAriim8pcZ",
        "outputId": "5b75fe71-bc76-4958-bc49-bc3e4929d538",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-27f8050fed2b>:159: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2-step: 0, loss adv: 14.59, loss cam: 0.15953, succeed: 0\n",
            "s2-step: 100, loss adv: 0.48, loss cam: 0.12832, succeed: 9\n",
            "s2-step: 200, loss adv: 0.44, loss cam: 0.12973, succeed: 9\n",
            "s2-step: 300, loss adv: 0.37, loss cam: 0.12878, succeed: 10\n",
            "s2-step: 400, loss adv: 0.35, loss cam: 0.12610, succeed: 10\n",
            "s2-step: 500, loss adv: 0.37, loss cam: 0.11934, succeed: 10\n",
            "s2-step: 600, loss adv: 0.31, loss cam: 0.11835, succeed: 10\n",
            "s2-step: 700, loss adv: 0.34, loss cam: 0.11849, succeed: 10\n",
            "s2-step: 800, loss adv: 0.34, loss cam: 0.11886, succeed: 10\n",
            "s2-step: 900, loss adv: 0.31, loss cam: 0.11531, succeed: 10\n",
            "s2-step: 1000, loss adv: 0.35, loss cam: 0.11353, succeed: 10\n",
            "s2-step: 1100, loss adv: 0.29, loss cam: 0.11306, succeed: 10\n",
            "s2-step: 1200, loss adv: 0.34, loss cam: 0.11143, succeed: 10\n",
            "s2-step: 1300, loss adv: 0.34, loss cam: 0.10997, succeed: 10\n",
            "s2-step: 1400, loss adv: 0.33, loss cam: 0.10690, succeed: 10\n"
          ]
        }
      ],
      "source": [
        "attack_cam('fold_1.npz', 'output_1.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge+"
      ],
      "metadata": {
        "id": "AIkBuC3JKOQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PGD_SAVE_PERIOD = 50\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(cam_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "    w = inverse_tanh_space(bx.clone().detach()).detach()\n",
        "    w.requires_grad_()\n",
        "\n",
        "    best_adv_images = bx.clone().detach()\n",
        "    best_L2 = 1e10*torch.ones((len(bx))).to('cuda')\n",
        "    prev_cost = 1e10\n",
        "    dim = len(bx.shape)\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "    dobj = {}\n",
        "\n",
        "    MSELoss = nn.MSELoss(reduction='none')\n",
        "    Flatten = nn.Flatten()\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "\n",
        "        pert = (adv_images - bx) * weights\n",
        "        adv_images = bx + torch.where(weights > 0.1, pert, torch.tensor(0.).to('cuda'))\n",
        "\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "        logits = model(pre_fn(adv_images))\n",
        "        f_loss = f(logits, by, config['kappa']).sum()\n",
        "\n",
        "        cost = L2_loss + 1e-4*f_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    optimizer = Adam([w], lr=0.01, amsgrad=True)\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "        c_now += c_inc\n",
        "\n",
        "        adv_images = tanh_space(w)\n",
        "        current_L2 = MSELoss(Flatten(adv_images),\n",
        "                                 Flatten(bx)).sum(dim=1)\n",
        "        L2_loss = current_L2.sum()\n",
        "\n",
        "\n",
        "        # adv_images = flow_obj(images, flows)\n",
        "        # flow_loss = flow_loss_obj(flows)\n",
        "\n",
        "        logits, cam = cam_forward(model_tup, forward_tup, adv_images, by)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logits, dim=-1), by, reduction='none')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = (diff * diff).mean(1)\n",
        "        total_loss = 2 * adv_loss + L2_loss + c_now * loss_cam\n",
        "\n",
        "        # record examples\n",
        "        # if i % PGD_SAVE_PERIOD == PGD_SAVE_PERIOD - 1:\n",
        "        #     cam_flatten_n = cam_flatten.view(*cam.size()).detach()\n",
        "        #     dobj[adv_step_template % (i + 1)] = adv_images.detach().cpu().numpy()\n",
        "        #     dobj[cam_step_template % (i + 1)] = cam.detach().cpu().numpy()\n",
        "        #     dobj[cam_n_step_template % (i + 1)] = cam_flatten_n.cpu().numpy()\n",
        "        #     dobj[logits_step_template % (i + 1)] = logits.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, pre = torch.max(logits.detach(), 1)\n",
        "        correct = (pre == by).float()\n",
        "\n",
        "        mask = (1-correct)*(best_L2 > current_L2.detach())\n",
        "        best_L2 = mask*current_L2.detach() + (1-mask)*best_L2\n",
        "\n",
        "        mask = mask.view([-1]+[1]*(dim-1))\n",
        "        best_adv_images = mask*adv_images.detach() + (1-mask)*best_adv_images\n",
        "\n",
        "        if i % 50 == 49:\n",
        "            cam_flatten_n = cam_flatten.view(*cam.size()).detach()\n",
        "            dobj['adv_x'] = best_adv_images.detach().cpu().numpy()\n",
        "            dobj['adv_cam'] = cam_flatten_n.detach().cpu().numpy()\n",
        "            dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "            dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "            dobj['tcam'] = cam_benign\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = loss_cam.mean().item()\n",
        "                loss_adv_mu = adv_loss.mean().item()\n",
        "                # flow_loss = flow_tvloss_obj(flows).mean().item()\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                adv_loss = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss cam: %.5f, succeed: %d' %\n",
        "                  (i, adv_loss, loss_cam, num_succeed))\n",
        "\n",
        "    return dobj\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam_2(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['model'] = 'resnet50'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 1500\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "    config['kappa'] = 0\n",
        "    config['tau'] = 0.0005\n",
        "\n",
        "    # if(not os.path.exists('cam_attack_output/')):\n",
        "    #   os.mkdir('cam_attack_output')\n",
        "\n",
        "    attack(config)\n"
      ],
      "metadata": {
        "id": "8JIMVfUlKN3p"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_cam_2('fold_1.npz', 'output_1.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "XOlq9cNZKjRc",
        "outputId": "f2a6e1ab-7dd2-414d-a9fc-a14c4ca3f350"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-07a81dbb3c5f>:126: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2-step: 0, loss adv: 18.37, loss cam: 0.16006, succeed: 0\n",
            "s2-step: 100, loss adv: 0.41, loss cam: 0.13733, succeed: 9\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9ddf70146db4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattack_cam_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fold_1.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-07a81dbb3c5f>\u001b[0m in \u001b[0;36mattack_cam_2\u001b[0;34m(data_path, fName)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m#   os.mkdir('cam_attack_output')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-07a81dbb3c5f>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_yt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mdobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;31m# dobj['bcam'] = cam_target[si:ei]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0msave_dobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-07a81dbb3c5f>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(config, model_tup, forward_tup, batch_tup, cam_benign)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SoGyRgX8qB4"
      },
      "outputs": [],
      "source": [
        "# def resize(img, new_size=(224, 224)):\n",
        "#   img = np.uint8(255 * img.transpose([1, 2, 0]))\n",
        "#   img = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
        "#   img = img.transpose([2, 0, 1])\n",
        "#   return np.float32(img / 255.)\n",
        "\n",
        "# def plot(img, heatmap):\n",
        "#   m1 = np.uint8(255 * cv2.resize(heatmap, (224, 224), interpolation=cv2.INTER_LINEAR))\n",
        "#   m1 = cv2.applyColorMap(m1, cv2.COLORMAP_JET)\n",
        "#   m1 = np.float32(m1 / 255.).transpose([2, 0, 1])[::-1]\n",
        "#   m1 = (img + m1)\n",
        "#   m1 = m1 / m1.max()\n",
        "#   # plt.imshow(m1.transpose((1,2,0)))\n",
        "#   return np.float32(m1).transpose((1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8tJB5gpJkna"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}