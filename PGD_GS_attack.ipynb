{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HtWDgLl9jDw1"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from shapely.affinity import rotate\n",
        "from shapely.geometry import box\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "14LTV-_usR4k"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QM4ZX-MOhc39"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.classes   = os.listdir(path)\n",
        "        self.path      = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = int(self.file_list[idx][2].split('/')[1])\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "        return im, classCategory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8tfmHFj05uc6"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = SoftReLU()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = SoftReLU()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = SoftReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet50_soft(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eEElwNkB51xs"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.resnet import resnet50\n",
        "from torchvision.models.densenet import densenet169\n",
        "\n",
        "def load_model():\n",
        "    model = resnet50(True)\n",
        "    model.to('cuda')\n",
        "    model.train(False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_SFzbI30utHF"
      },
      "outputs": [],
      "source": [
        "# model = load_model()\n",
        "# bx_nps, by_nps = [], []\n",
        "\n",
        "# for i, (bx, by) in enumerate(loader):\n",
        "#   bx_np, by_np = bx.numpy(), by.numpy()\n",
        "#   bx, by = [t.to('cuda') for t in (bx, by)]\n",
        "#   bx = imagenet_normalize(bx)\n",
        "#   bp_np = model(bx)\n",
        "#   bp_np = bp_np.argmax(1).to('cpu').numpy()\n",
        "#   succeed = by_np == bp_np\n",
        "#   bx_nps.append(bx_np[succeed])\n",
        "#   by_nps.append(by_np[succeed])\n",
        "\n",
        "# bx_np = np.concatenate(bx_nps)\n",
        "# by_np = np.concatenate(by_nps)\n",
        "# byt = np.random.randint(1, 1000, len(by_np)).astype(np.int64)\n",
        "# byt = np.mod(by_np + byt, 1000)\n",
        "\n",
        "# num_folds = min(len(bx_np) // 10, 5)\n",
        "# print(len(bx_np), by_np, byt)\n",
        "\n",
        "# for i in range(num_folds):\n",
        "#   si, ei = i * 10, (i + 1) * 10\n",
        "#   sl = slice(si, ei)\n",
        "#   np.savez(os.path.join(save_dir, 'fold_%d.npz' % (i + 1)), img_x=bx_np[sl],\n",
        "#                  img_y=by_np[sl], img_yt=byt[sl])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjQY2dyxl2Hi"
      },
      "source": [
        "Generate Benign Gradient *Saliency*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0O7lmyRUmCJF"
      },
      "outputs": [],
      "source": [
        "def imagenet_resize_postfn(grad):\n",
        "    # grad = grad.abs().max(1, keepdim=True)[0].squeeze(1) # remove squeeze and uncomment next line\n",
        "    grad = grad.abs().max(1, keepdim=True)[0]\n",
        "    grad = F.avg_pool2d(grad, 4).squeeze(1)\n",
        "    shape = grad.shape\n",
        "    grad = grad.view(len(grad), -1)\n",
        "    grad_min = grad.min(1, keepdim=True)[0]\n",
        "    grad = grad - grad_min\n",
        "    grad_max = grad.max(1, keepdim=True)[0]\n",
        "    grad = grad / torch.max(grad_max, torch.tensor([1e-8], device='cuda'))\n",
        "    return grad.view(*shape)\n",
        "\n",
        "\n",
        "def generate_gs_per_batches(model_tup, bx, by, post_fn=None, keep_grad=False):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    bxp = pre_fn(bx)\n",
        "    logit = model(bxp)\n",
        "    loss = F.nll_loss(F.log_softmax(logit), by)\n",
        "    grad = autograd.grad([loss], [bx], create_graph=keep_grad)[0]\n",
        "    if post_fn is not None:\n",
        "        grad = post_fn(grad)\n",
        "    return grad\n",
        "\n",
        "\n",
        "def generate_gs(model_tup, x, y, post_fn=None, keep_grad=False, batch_size=10, device='cuda'):\n",
        "    n = len(x)\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "    generated = []\n",
        "    for i in range(n_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(n, si + batch_size)\n",
        "        bx, by = x[si:ei], y[si:ei]\n",
        "        bx, by = torch.tensor(bx, device=device, requires_grad=True), torch.tensor(by, device='cuda')\n",
        "        generated.append(generate_gs_per_batches(\n",
        "            model_tup, bx, by, post_fn=post_fn,\n",
        "            keep_grad=keep_grad).detach().cpu().numpy())\n",
        "    generated = np.concatenate(generated, axis=0)\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5A5bli3pl0AJ"
      },
      "outputs": [],
      "source": [
        "def load_model():\n",
        "    pre_fn = imagenet_normalize\n",
        "    model = densenet169(True)\n",
        "    shape = (224, 224)\n",
        "\n",
        "\n",
        "    model.train(False)\n",
        "    model.cuda()\n",
        "    return model, pre_fn, shape\n",
        "\n",
        "\n",
        "def generate(path, filename):\n",
        "    # if(not os.path.exists('gdrive/MyDrive/GS/Resnet/')):\n",
        "    #   os.mkdir('gdrive/MyDrive/GS/Resnet/')\n",
        "    model_tup = load_model()\n",
        "\n",
        "    dobj = np.load(path)\n",
        "    img_x, img_y, img_yt = dobj['img_x'], dobj['img_y'], dobj['img_yt']\n",
        "    # print(img_x.shape)\n",
        "    benign_gs = generate_gs(model_tup, img_x, img_y, imagenet_resize_postfn, False, batch_size=10)\n",
        "    # print(benign_gs.shape)\n",
        "    save_dobj = {'img_x': img_x, 'img_y': img_y, 'benign_gs': benign_gs, 'img_yt': img_yt}\n",
        "    np.savez('gdrive/MyDrive/GS/Densenet/{}'.format(filename), **save_dobj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kO0Zsh2fkwXC"
      },
      "outputs": [],
      "source": [
        "# generate('data/fold_1.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PcM4PU7DskfK"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x2nU-0j6Arif"
      },
      "outputs": [],
      "source": [
        "def imagenet_resize_postfn(grad):\n",
        "    grad = grad.abs().max(1, keepdim=True)[0]\n",
        "    grad = F.avg_pool2d(grad, 4).squeeze(1)\n",
        "    shape = grad.shape\n",
        "    grad = grad.view(len(grad), -1)\n",
        "    grad_min = grad.min(1, keepdim=True)[0]\n",
        "    grad = grad - grad_min\n",
        "    grad_max = grad.max(1, keepdim=True)[0]\n",
        "    grad = grad / torch.max(grad_max, torch.tensor([1e-8], device='cuda'))\n",
        "    return grad.view(*shape)\n",
        "\n",
        "\n",
        "def generate_gs_per_batches(model_tup, bx, by, post_fn=None, keep_grad=False):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    bxp = pre_fn(bx)\n",
        "    logit = model(bxp)\n",
        "    loss = F.nll_loss(F.log_softmax(logit), by)\n",
        "    grad = autograd.grad([loss], [bx], create_graph=keep_grad)[0]\n",
        "    if post_fn is not None:\n",
        "        grad = post_fn(grad)\n",
        "    return grad\n",
        "\n",
        "\n",
        "def generate_gs(model_tup, x, y, post_fn=None, keep_grad=False, batch_size=48, device='cuda'):\n",
        "    n = len(x)\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "    generated = []\n",
        "    for i in range(n_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(n, si + batch_size)\n",
        "        bx, by = x[si:ei], y[si:ei]\n",
        "        bx, by = torch.tensor(bx, device=device, requires_grad=True), torch.tensor(by, device='cuda')\n",
        "        generated.append(generate_gs_per_batches(\n",
        "            model_tup, bx, by, post_fn=post_fn,\n",
        "            keep_grad=keep_grad).detach().cpu().numpy())\n",
        "    generated = np.concatenate(generated, axis=0)\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge"
      ],
      "metadata": {
        "id": "VyEv3NBaXIK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "import time\n",
        "\n",
        "def load_model(device):\n",
        "    model = resnet50(pretrained=True)\n",
        "    model_ref = resnet50_soft(pretrained=True)\n",
        "\n",
        "    # nn.DataParallel(model).load_state_dict(torch.load(CIFAR10_RESNET50_CKPT_PATH,\n",
        "    #                                                   lambda storage, location: storage)['net'])\n",
        "\n",
        "    model.to(device)\n",
        "    model.train(False)\n",
        "    model_ref.to(device)\n",
        "    model_ref.train(False)\n",
        "\n",
        "    freeze_model(model)\n",
        "    freeze_model(model_ref)\n",
        "    return (model, imagenet_normalize), (model_ref, imagenet_normalize)\n",
        "\n",
        "\n",
        "def attack_batch(cs, steps, model_tup, ref_model_tup, bx, by, bm, device):\n",
        "    n = len(bx)\n",
        "    by_np = by.to('cpu').numpy()\n",
        "    model, pre_fn = model_tup\n",
        "    ref_model_tup = (ref_model_tup[0], lambda x: x)\n",
        "    # print(bm[0].shape)\n",
        "    best_dist = np.full((n, ), np.inf, dtype=np.float32)\n",
        "    best_adv = bx.cpu().numpy()\n",
        "    best_adv_gs = np.zeros((n, 56, 56), dtype=np.float32)\n",
        "    best_adv_conf = np.zeros((n,), dtype=np.float32)\n",
        "\n",
        "    bx0 = bx.clone()\n",
        "    bx = bx.clone().requires_grad_()\n",
        "\n",
        "    bx1 = bx.cpu().detach().clone()\n",
        "\n",
        "\n",
        "    unpert_gray = bx1.numpy().mean(axis = 1, keepdims=True)\n",
        "\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "\n",
        "    weights = torch.tensor(edges).to(device)\n",
        "\n",
        "\n",
        "    for i in range(300):\n",
        "        bx_p = pre_fn(bx)\n",
        "        logit = model(bx_p)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logit), by, reduction='sum')\n",
        "        final_grad = autograd.grad([adv_loss], [bx])[0]\n",
        "\n",
        "        bx.data = bx.data - weights * 1. / 255 * final_grad.sign()\n",
        "        r = bx.data - bx0\n",
        "        r.clamp_(-0.031, 0.031)\n",
        "        bx.data = bx0 + r\n",
        "        del final_grad\n",
        "\n",
        "    bx_adv_start = bx.detach().clone()\n",
        "    bx = bx_adv_start.clone().requires_grad_()\n",
        "\n",
        "    label_indices = np.arange(0, n, dtype=np.int64)\n",
        "    for c, num_step in zip(cs, steps):\n",
        "        for i in range(num_step):\n",
        "            conf_base = 0.95 + i / num_step * 0.04\n",
        "            conf = np.random.uniform(conf_base, 1, size=(n, )).astype(np.float32)\n",
        "            conf_mat = ((1 - conf) / 9.).reshape((n, 1)).repeat(1000, 1)\n",
        "            conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "            bx_p = pre_fn(bx)\n",
        "            logit = model(bx_p)\n",
        "            # print(F.log_softmax(logit))\n",
        "            # print(len(F.log_softmax(logit)[0]))\n",
        "            by_one = torch.tensor(conf_mat, device='cuda')\n",
        "            adv_loss = (-by_one * F.log_softmax(logit)).sum()\n",
        "\n",
        "            adv_gs = generate_gs_per_batches(ref_model_tup, bx_p, by, post_fn=imagenet_resize_postfn,\n",
        "                                             keep_grad=True)\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                with torch.no_grad():\n",
        "                    prob = F.softmax(logit).gather(1, by.view(n, -1)).view(n)\n",
        "                prob = prob.cpu().numpy()\n",
        "                now_gs = generate_gs_per_batches(model_tup, bx, by, post_fn=imagenet_resize_postfn)\n",
        "                print(now_gs.shape)\n",
        "                diff = now_gs.detach() - bm\n",
        "                now_dist = (diff * diff).view(n, -1).sum(1).cpu().numpy()\n",
        "                mask = np.logical_and(prob > 0.8, now_dist < best_dist)\n",
        "                indices_np = np.nonzero(mask)[0]\n",
        "                indices = torch.tensor(indices_np, device=device)\n",
        "                best_dist[indices_np] = now_dist[indices_np]\n",
        "                best_adv[indices_np] = bx.detach()[indices].cpu().numpy()\n",
        "                best_adv_gs[indices_np] = now_gs[indices].cpu().numpy()\n",
        "                best_adv_conf[indices_np] = prob[indices_np]\n",
        "\n",
        "            diff = adv_gs - bm\n",
        "            int_loss = (diff * diff).view(n, -1).sum()\n",
        "            loss = adv_loss + c * int_loss\n",
        "            final_grad = autograd.grad([loss], [bx])[0]\n",
        "\n",
        "            bx.data = bx.data - 1./255 * final_grad.sign()\n",
        "            r = bx.data - bx0\n",
        "            r.clamp_(-0.031, 0.031)\n",
        "            bx.data = bx0 + r\n",
        "            bx.data.clamp_(0, 1)\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                succeed_indices = np.nonzero(best_dist < np.inf)[0]\n",
        "\n",
        "                print('c', c, 'step', i,\n",
        "                      'succeed:', len(succeed_indices), 'conf:', np.mean(best_adv_conf[succeed_indices]),\n",
        "                      'dist', np.mean(best_dist[succeed_indices]))\n",
        "\n",
        "            del final_grad, loss, int_loss\n",
        "    return dict(best_dist=best_dist, best_adv=best_adv, best_adv_gs=best_adv_gs, best_adv_conf=best_adv_conf)\n",
        "\n",
        "\n",
        "def analyze_batch(model_tup, bx, by, bm, result):\n",
        "    n = len(bx)\n",
        "    succeed = (result['best_dist'] < np.inf).astype(np.int64)\n",
        "    diff = (bm - result['best_adv_gs']).reshape((n, -1))\n",
        "    return dict(succeed=succeed, l2_dist=np.linalg.norm(diff, 2, axis=1),\n",
        "                l1_dist=np.linalg.norm(diff, 1, axis=1))\n",
        "\n",
        "\n",
        "def main(data_path, save_path, batch_size, device, steps, cs, begin, end):\n",
        "    model_tup, ref_model_tup = load_model(device)\n",
        "    dobj = np.load(data_path)\n",
        "    img_x, img_y, img_m = dobj['img_x'], dobj['img_yt'], dobj['benign_gs']\n",
        "    # print(img_m.shape)\n",
        "    if begin != -1 and end != -1:\n",
        "        beg, end = begin, end\n",
        "        img_x, img_y, img_m = img_x[beg:end], img_y[beg:end], img_m[beg:end]\n",
        "    n, batch_size = len(img_x), batch_size\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "    results = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(n, si + batch_size)\n",
        "        bx_np, by_np, bm_np = img_x[si:ei], img_y[si:ei], img_m[si:ei]\n",
        "        bx, by, bm = [torch.tensor(arr, device=device) for arr in (bx_np, by_np, bm_np)]\n",
        "        result = attack_batch(cs, steps, model_tup, ref_model_tup, bx, by, bm, device)\n",
        "        result.update(analyze_batch(model_tup, bx_np, by_np, bm_np, result))\n",
        "        results.append(result)\n",
        "\n",
        "    etimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(results[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in results], axis=0)\n",
        "\n",
        "    save_dobj['time'] = etimated_time\n",
        "    save_dobj['img_x'] = img_x\n",
        "    save_dobj['img_y'] = dobj['img_y']\n",
        "    save_dobj['img_yt'] = img_y\n",
        "    save_dobj['benign_gs'] = img_m\n",
        "    np.savez(save_path, **save_dobj)\n",
        "\n",
        "\n",
        "def start_attack_1(data_path, filename):\n",
        "    # data_path = 'benign_gs_data/benign_gs_fold_1.npz'\n",
        "    save_path = f'{filename}'\n",
        "    batch_size = 10\n",
        "    steps = [301, 201, 101, 101, 50]\n",
        "    cs = [0.001, 0.004, 0.01, 0.05, 0.07]\n",
        "    begin = -1\n",
        "    end = -1\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    main(data_path, save_path, batch_size, device, steps, cs, begin, end)"
      ],
      "metadata": {
        "id": "DJX9kDXaXH-D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_attack_1('gs.npz', 'output_1.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "ka1nU13aXrl4",
        "outputId": "36a327ec-b773-400d-cb23-bf11fab00038"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-dd6f0dba5e45>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  adv_loss = F.nll_loss(F.log_softmax(logit), by, reduction='sum')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b7f38a0a1b63>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_attack_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gs.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-dd6f0dba5e45>\u001b[0m in \u001b[0;36mstart_attack_1\u001b[0;34m(data_path, filename)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-dd6f0dba5e45>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_path, save_path, batch_size, device, steps, cs, begin, end)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_model_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-dd6f0dba5e45>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(cs, steps, model_tup, ref_model_tup, bx, by, bm, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mfinal_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfinal_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdvEdge+"
      ],
      "metadata": {
        "id": "FDIGceZbXGZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZUmo_MTaSsZW"
      },
      "outputs": [],
      "source": [
        "import skimage\n",
        "\n",
        "def load_model(device):\n",
        "    model = resnet50(pretrained=True)\n",
        "    model_ref = resnet50_soft(pretrained=True)\n",
        "\n",
        "    # nn.DataParallel(model).load_state_dict(torch.load(CIFAR10_RESNET50_CKPT_PATH,\n",
        "    #                                                   lambda storage, location: storage)['net'])\n",
        "\n",
        "    model.to(device)\n",
        "    model.train(False)\n",
        "    model_ref.to(device)\n",
        "    model_ref.train(False)\n",
        "\n",
        "    freeze_model(model)\n",
        "    freeze_model(model_ref)\n",
        "    return (model, imagenet_normalize), (model_ref, imagenet_normalize)\n",
        "\n",
        "\n",
        "def attack_batch(cs, steps, model_tup, ref_model_tup, bx, by, bm, device):\n",
        "    n = len(bx)\n",
        "    by_np = by.to('cpu').numpy()\n",
        "    model, pre_fn = model_tup\n",
        "    ref_model_tup = (ref_model_tup[0], lambda x: x)\n",
        "\n",
        "    best_dist = np.full((n, ), np.inf, dtype=np.float32)\n",
        "    best_adv = bx.cpu().numpy()\n",
        "    best_adv_gs = np.zeros((n, 56, 56), dtype=np.float32)\n",
        "    best_adv_conf = np.zeros((n,), dtype=np.float32)\n",
        "\n",
        "    bx0 = bx.clone()\n",
        "    bx = bx.clone().requires_grad_()\n",
        "\n",
        "    bx1 = bx.cpu().detach().clone()\n",
        "\n",
        "\n",
        "    unpert_gray = bx1.numpy().mean(axis = 1, keepdims=True)\n",
        "\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "      edges[index] = filters.sobel(image.squeeze(0))\n",
        "\n",
        "    weights = torch.tensor(edges).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(200):\n",
        "        bx_p = pre_fn(bx)\n",
        "        logit = model(bx_p)\n",
        "        adv_loss = F.nll_loss(F.log_softmax(logit), by, reduction='sum')\n",
        "        final_grad = autograd.grad([adv_loss], [bx])[0]\n",
        "\n",
        "        bx.data = bx.data - 1. / 255 * torch.where(weights > 0.1, final_grad.sign(), torch.tensor(0.).to(device))\n",
        "        r = bx.data - bx0\n",
        "        r.clamp_(-0.031, 0.031)\n",
        "        bx.data = bx0 + r\n",
        "        del final_grad\n",
        "\n",
        "    bx_adv_start = bx.detach().clone()\n",
        "    bx = bx_adv_start.clone().requires_grad_()\n",
        "\n",
        "    label_indices = np.arange(0, n, dtype=np.int64)\n",
        "\n",
        "    for c, num_step in zip(cs, steps):\n",
        "        for i in range(num_step):\n",
        "            conf_base = 0.95 + i / num_step * 0.04\n",
        "            conf = np.random.uniform(conf_base, 1, size=(n, )).astype(np.float32)\n",
        "            conf_mat = ((1 - conf) / 9.).reshape((n, 1)).repeat(1000, 1)\n",
        "            conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "            bx_p = pre_fn(bx)\n",
        "            logit = model(bx_p)\n",
        "            # print(F.log_softmax(logit))\n",
        "            # print(len(F.log_softmax(logit)[0]))\n",
        "            by_one = torch.tensor(conf_mat, device='cuda')\n",
        "            adv_loss = (-by_one * F.log_softmax(logit)).sum()\n",
        "\n",
        "            adv_gs = generate_gs_per_batches(ref_model_tup, bx_p, by, post_fn=imagenet_resize_postfn,\n",
        "                                             keep_grad=True)\n",
        "\n",
        "            if i % 2 == 0:\n",
        "                with torch.no_grad():\n",
        "                    prob = F.softmax(logit).gather(1, by.view(n, -1)).view(n)\n",
        "                prob = prob.cpu().numpy()\n",
        "                now_gs = generate_gs_per_batches(model_tup, bx, by, post_fn=imagenet_resize_postfn)\n",
        "                print(now_gs.shape)\n",
        "                diff = now_gs.detach() - bm\n",
        "                now_dist = (diff * diff).view(n, -1).sum(1).cpu().numpy()\n",
        "                mask = np.logical_and(prob > 0.8, now_dist < best_dist)\n",
        "                indices_np = np.nonzero(mask)[0]\n",
        "                indices = torch.tensor(indices_np, device=device)\n",
        "                best_dist[indices_np] = now_dist[indices_np]\n",
        "                best_adv[indices_np] = bx.detach()[indices].cpu().numpy()\n",
        "                best_adv_gs[indices_np] = now_gs[indices].cpu().numpy()\n",
        "                best_adv_conf[indices_np] = prob[indices_np]\n",
        "\n",
        "            diff = adv_gs - bm\n",
        "            int_loss = (diff * diff).view(n, -1).sum()\n",
        "            loss = adv_loss + c * int_loss\n",
        "            final_grad = autograd.grad([loss], [bx])[0]\n",
        "\n",
        "            bx.data = bx.data - 1./255 * final_grad.sign()\n",
        "            r = bx.data - bx0\n",
        "            r.clamp_(-0.031, 0.031)\n",
        "            bx.data = bx0 + r\n",
        "            bx.data.clamp_(0, 1)\n",
        "\n",
        "            if i % 2 == 0:\n",
        "                succeed_indices = np.nonzero(best_dist < np.inf)[0]\n",
        "\n",
        "                print('c', c, 'step', i,\n",
        "                      'succeed:', len(succeed_indices), 'conf:', np.mean(best_adv_conf[succeed_indices]),\n",
        "                      'dist', np.mean(best_dist[succeed_indices]))\n",
        "\n",
        "            del final_grad, loss, int_loss\n",
        "    return dict(best_dist=best_dist, best_adv=best_adv, best_adv_gs=best_adv_gs, best_adv_conf=best_adv_conf)\n",
        "\n",
        "\n",
        "def analyze_batch(model_tup, bx, by, bm, result):\n",
        "    n = len(bx)\n",
        "    succeed = (result['best_dist'] < np.inf).astype(np.int64)\n",
        "    diff = (bm - result['best_adv_gs']).reshape((n, -1))\n",
        "    return dict(succeed=succeed, l2_dist=np.linalg.norm(diff, 2, axis=1),\n",
        "                l1_dist=np.linalg.norm(diff, 1, axis=1))\n",
        "\n",
        "\n",
        "def main(data_path, save_path, batch_size, device, steps, cs, begin, end):\n",
        "    model_tup, ref_model_tup = load_model(device)\n",
        "    dobj = np.load(data_path)\n",
        "    img_x, img_y, img_m = dobj['img_x'], dobj['img_yt'], dobj['benign_gs']\n",
        "    # print(img_m.shape)\n",
        "    if begin != -1 and end != -1:\n",
        "        beg, end = begin, end\n",
        "        img_x, img_y, img_m = img_x[beg:end], img_y[beg:end], img_m[beg:end]\n",
        "    n, batch_size = len(img_x), batch_size\n",
        "    n_batches = (n + batch_size - 1) // batch_size\n",
        "    results = []\n",
        "    for i in range(n_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(n, si + batch_size)\n",
        "        bx_np, by_np, bm_np = img_x[si:ei], img_y[si:ei], img_m[si:ei]\n",
        "        bx, by, bm = [torch.tensor(arr, device=device) for arr in (bx_np, by_np, bm_np)]\n",
        "        result = attack_batch(cs, steps, model_tup, ref_model_tup, bx, by, bm, device)\n",
        "        result.update(analyze_batch(model_tup, bx_np, by_np, bm_np, result))\n",
        "        results.append(result)\n",
        "\n",
        "    keys = list(results[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in results], axis=0)\n",
        "    save_dobj['img_x'] = img_x\n",
        "    save_dobj['img_y'] = dobj['img_y']\n",
        "    save_dobj['img_yt'] = img_y\n",
        "    save_dobj['benign_gs'] = img_m\n",
        "    np.savez(save_path, **save_dobj)\n",
        "\n",
        "\n",
        "def start_attack():\n",
        "    data_path = 'gs.npz'\n",
        "    save_path = 'output_1.npz'\n",
        "    batch_size = 10\n",
        "    steps = [301, 201, 101, 101, 101]\n",
        "    cs = [0.001, 0.004, 0.01, 0.05, 0.07]\n",
        "    begin = -1\n",
        "    end = -1\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    main(data_path, save_path, batch_size, device, steps, cs, begin, end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Djlcj8FzXgql",
        "outputId": "4835da6b-060d-4f79-b32b-a74866c0a294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c9656c862a82>:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  adv_loss = F.nll_loss(F.log_softmax(logit), by, reduction='sum')\n",
            "<ipython-input-20-c9656c862a82>:77: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  adv_loss = (-by_one * F.log_softmax(logit)).sum()\n",
            "<ipython-input-14-f369ac0ba094>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  loss = F.nll_loss(F.log_softmax(logit), by)\n",
            "<ipython-input-20-c9656c862a82>:84: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  prob = F.softmax(logit).gather(1, by.view(n, -1)).view(n)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 0 succeed: 9 conf: 0.9601243 dist 47.274277\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 2 succeed: 9 conf: 0.9601243 dist 47.274277\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 4 succeed: 9 conf: 0.9601243 dist 47.274277\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 6 succeed: 9 conf: 0.9599608 dist 45.74157\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 8 succeed: 9 conf: 0.9458065 dist 44.845535\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 10 succeed: 9 conf: 0.94330627 dist 44.26962\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 12 succeed: 9 conf: 0.94330627 dist 44.26962\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 14 succeed: 9 conf: 0.94330627 dist 44.26962\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 16 succeed: 9 conf: 0.94330627 dist 44.26962\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 18 succeed: 9 conf: 0.94645286 dist 40.503376\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 20 succeed: 9 conf: 0.94645286 dist 40.503376\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 22 succeed: 9 conf: 0.94645286 dist 40.503376\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 24 succeed: 9 conf: 0.944546 dist 37.08804\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 26 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 28 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 30 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 32 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 34 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 36 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 38 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 40 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 42 succeed: 9 conf: 0.95953095 dist 35.939995\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 44 succeed: 10 conf: 0.95408916 dist 39.858746\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 46 succeed: 10 conf: 0.95408916 dist 39.858746\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 48 succeed: 10 conf: 0.93781674 dist 39.715767\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 50 succeed: 10 conf: 0.93781674 dist 39.715767\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 52 succeed: 10 conf: 0.93781674 dist 39.715767\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 54 succeed: 10 conf: 0.93458164 dist 39.126118\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 56 succeed: 10 conf: 0.93458164 dist 39.126118\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 58 succeed: 10 conf: 0.93458164 dist 39.126118\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 60 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 62 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 64 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 66 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 68 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 70 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 72 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 74 succeed: 10 conf: 0.9377262 dist 38.246136\n",
            "torch.Size([10, 56, 56])\n",
            "c 0.001 step 76 succeed: 10 conf: 0.9377262 dist 38.246136\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-866bac57057d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-c9656c862a82>\u001b[0m in \u001b[0;36mstart_attack\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-c9656c862a82>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_path, save_path, batch_size, device, steps, cs, begin, end)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_m\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_model_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyze_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_tup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-c9656c862a82>\u001b[0m in \u001b[0;36mattack_batch\u001b[0;34m(cs, steps, model_tup, ref_model_tup, bx, by, bm, device)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mint_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mfinal_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfinal_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start_attack()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpBJgCJxpNu5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXgMnqnEFKib"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}