{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HtWDgLl9jDw1"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import random\n",
        "from shutil import copy2\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import math\n",
        "from torch.utils import model_zoo\n",
        "\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mATBuq-u7XgX"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.set_device(2)\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "14LTV-_usR4k"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def imagenet_normalize(t, mean=None, std=None):\n",
        "    if mean is None:\n",
        "        mean = IMAGENET_MEAN\n",
        "    if std is None:\n",
        "        std= IMAGENET_STD\n",
        "\n",
        "    ts = []\n",
        "    for i in range(3):\n",
        "        ts.append(torch.unsqueeze((t[:, i] - mean[i]) / std[i], 1))\n",
        "    return torch.cat(ts, dim=1)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QM4ZX-MOhc39"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.classes   = os.listdir(path)\n",
        "        self.path      = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = int(self.file_list[idx][2].split('/')[1])\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "        return im, classCategory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8tfmHFj05uc6"
      },
      "outputs": [],
      "source": [
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "}\n",
        "\n",
        "\n",
        "#\n",
        "# AlexNet | begin\n",
        "#\n",
        "\n",
        "ALEXNET_NAME_MAP = {\n",
        "    \"conv1.weight\": \"features.0.weight\",\n",
        "    \"conv1.bias\": \"features.0.bias\",\n",
        "    \"conv2.weight\": \"features.3.weight\",\n",
        "    \"conv2.bias\": \"features.3.bias\",\n",
        "    \"conv3.weight\": \"features.6.weight\",\n",
        "    \"conv3.bias\": \"features.6.bias\",\n",
        "    \"conv4.weight\": \"features.8.weight\",\n",
        "    \"conv4.bias\": \"features.8.bias\",\n",
        "    \"conv5.weight\": \"features.10.weight\",\n",
        "    \"conv5.bias\": \"features.10.bias\",\n",
        "    \"fc1.weight\": \"classifier.1.weight\",\n",
        "    \"fc1.bias\": \"classifier.1.bias\",\n",
        "    \"fc2.weight\": \"classifier.4.weight\",\n",
        "    \"fc2.bias\": \"classifier.4.bias\",\n",
        "    \"fc3.weight\": \"classifier.6.weight\",\n",
        "    \"fc3.bias\": \"classifier.6.bias\"\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        # pooling layers\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        out['c1'] = self.conv1(x)\n",
        "        out['r1'] = F.relu(out['c1'])\n",
        "        out['p1'] = self.pool1(out['r1'])\n",
        "        out['r2'] = F.relu(self.conv2(out['p1']))\n",
        "        out['p2'] = self.pool2(out['r2'])\n",
        "        out['r3'] = F.relu(self.conv3(out['p2']))\n",
        "        out['r4'] = F.relu(self.conv4(out['r3']))\n",
        "        out['r5'] = F.relu(self.conv5(out['r4']))\n",
        "        out['p5'] = self.pool5(out['r5'])\n",
        "        out['fc1'] = F.relu(self.fc1(out['p5'].view(1, -1)))\n",
        "        out['fc2'] = F.relu(self.fc2(out['fc1']))\n",
        "        out['fc3'] = self.fc3(out['fc2'])\n",
        "\n",
        "        if out_keys is None:\n",
        "            return out['fc3']\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def convert_alexnet_weights(src_state, dest_state):\n",
        "    for key in dest_state:\n",
        "        if key in ALEXNET_NAME_MAP:\n",
        "            dest_state[key] = deepcopy(src_state[ALEXNET_NAME_MAP[key]])\n",
        "    return dest_state\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        src_state = model_zoo.load_url(model_urls['alexnet'])\n",
        "        dest_state = convert_alexnet_weights(src_state, model.state_dict())\n",
        "        model.load_state_dict(dest_state)\n",
        "    return model\n",
        "\n",
        "#\n",
        "# AlexNet | end\n",
        "#\n",
        "\n",
        "#\n",
        "# ResNet | begin\n",
        "#\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out = {}\n",
        "        x = self.conv1(x)\n",
        "        out[\"c1\"] = x\n",
        "        x = self.bn1(x)\n",
        "        out[\"bn1\"] = x\n",
        "        x = self.relu(x)\n",
        "        out[\"r1\"] = x\n",
        "        x = self.maxpool(x)\n",
        "        out[\"p1\"] = x\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        out[\"l1\"] = x\n",
        "        x = self.layer2(x)\n",
        "        out[\"l2\"] = x\n",
        "        x = self.layer3(x)\n",
        "        out[\"l3\"] = x\n",
        "        x = self.layer4(x)\n",
        "        out[\"l4\"] = x\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        out[\"gvp\"] = x\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        out[\"fc\"] = x\n",
        "\n",
        "        if out_keys is None:\n",
        "            return x\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out[key]\n",
        "        return res\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# ResNet | end\n",
        "\n",
        "\n",
        "# DenseNet | begin\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet169'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet201'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet161'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = super(_DenseLayer, self).forward(x)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([x, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        out_dict = {}\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out_dict['l'] = out\n",
        "        out = F.avg_pool2d(out, kernel_size=7, stride=1)\n",
        "        out_dict['gvp'] = out\n",
        "        out = out.view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        out_dict['fc'] = out\n",
        "        if out_keys is None:\n",
        "            return out\n",
        "\n",
        "        res = {}\n",
        "        for key in out_keys:\n",
        "            res[key] = out_dict[key]\n",
        "        return res\n",
        "\n",
        "# DenseNet | end\n",
        "\n",
        "\n",
        "def get_gaussian_blur_kernel(ksize, sigma):\n",
        "    ker = cv2.getGaussianKernel(ksize, sigma).astype(np.float32)\n",
        "    blur_kernel = (ker * ker.T)[None, None]\n",
        "    blur_kernel = torch.tensor(blur_kernel)\n",
        "\n",
        "    return blur_kernel\n",
        "\n",
        "\n",
        "def gaussian_blur(x, ksize, sigma):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "    :param x: torch.tensor (n, c, h, w), will padding with reflection\n",
        "    :param ksize: int\n",
        "    :param sigma: int\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    psize = int((ksize - 1) / 2)\n",
        "    blur_kernel = get_gaussian_blur_kernel(ksize, sigma)\n",
        "    x_padded = F.pad(x, [psize] * 4, mode=\"reflect\")\n",
        "    blurs = []\n",
        "    for i in range(3):\n",
        "        blurs.append(F.conv2d(x_padded[:, i, None], blur_kernel))\n",
        "    blurred = torch.cat(blurs, 1)\n",
        "\n",
        "    return blurred\n",
        "\n",
        "\n",
        "class GuidedBackpropReLU(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        positive_mask = (input > 0).type_as(input)\n",
        "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
        "        ctx.save_for_backward(input, output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, output = ctx.saved_tensors\n",
        "        grad_input = None\n",
        "\n",
        "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
        "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
        "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
        "\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "\n",
        "### SoftReLU\n",
        "\n",
        "\n",
        "class SoftReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super(SoftReLU, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # mask = (x > 0).float()\n",
        "        # return torch.sqrt(x * x + self.eps) * mask\n",
        "        return SoftReLUFunc.apply(x)\n",
        "\n",
        "\n",
        "class SoftReLUFunc(autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # v2\n",
        "        x,  = ctx.saved_tensors\n",
        "        # x2 = x * x\n",
        "        grad_input = grad_output.clone()\n",
        "        i1 = (x < 0)\n",
        "        i2 = x >= 0\n",
        "        xi1 = x[i1]\n",
        "        xi2 = x[i2]\n",
        "        n1, n2 = xi1.numel(), xi2.numel()\n",
        "        assert n1 + n2 == x.numel()\n",
        "        if n1 > 0:\n",
        "            xi12 = xi1 * xi1\n",
        "            new_v = xi1 / torch.sqrt(xi12 + 1e-4) + 1\n",
        "            grad_input[i1] = grad_input[i1] * new_v\n",
        "        if n2 > 0:\n",
        "            xi22 = xi2 * xi2\n",
        "            new_v = xi2 / torch.sqrt(xi22 + 1e-4)\n",
        "            grad_input[i2] = grad_input[i2] * new_v\n",
        "        return grad_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eEElwNkB51xs"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.resnet import resnet50\n",
        "\n",
        "def load_model():\n",
        "    model = resnet50(True)\n",
        "    model.to('cuda')\n",
        "    model.train(False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYgw6hR3F95Y"
      },
      "source": [
        "**CAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zUargpoaGcKo"
      },
      "outputs": [],
      "source": [
        "class CAM(object):\n",
        "\n",
        "    def __init__(self, model, output_keys=None):\n",
        "        self.model = model\n",
        "        self.model.cuda()\n",
        "        self.model.train(False)\n",
        "        if output_keys is not None:\n",
        "            self.output_keys = list(output_keys)\n",
        "        else:\n",
        "            self.output_keys = [\"l4\", \"gvp\", \"fc\"]\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        if out_keys is None:\n",
        "            out_keys = self.output_keys\n",
        "        res = self.model(x, out_keys)\n",
        "\n",
        "        rets = [res[key] for key in out_keys]\n",
        "        return rets\n",
        "\n",
        "    def __call__(self, x, y=None, out_keys=None):\n",
        "        if y is None:\n",
        "            with torch.no_grad():\n",
        "                _, _, logits = self.forward(x, out_keys=out_keys)\n",
        "                logits = logits.cpu().numpy()[0]\n",
        "            true_label = int(np.argmax(logits))\n",
        "            y = torch.tensor([true_label]).cuda()\n",
        "\n",
        "        l4, gvp, logits = self.forward(x)\n",
        "        wc = self.model.fc.weight[y].view(1, -1, 1, 1)\n",
        "        prod = (wc * l4).sum(1)\n",
        "\n",
        "        return logits, prod\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nivfgPQCGrz9"
      },
      "outputs": [],
      "source": [
        "def to_mask(m):\n",
        "    m = m - m.min()\n",
        "    m /= m.max()\n",
        "    return m\n",
        "\n",
        "\n",
        "def make_cam(x, m):\n",
        "    mask_x = cv2.applyColorMap(np.uint8(255. * cv2.resize(m, (224, 224))), cv2.COLORMAP_JET).transpose([2, 0, 1])[::-1]\n",
        "    mask_x = np.float32(mask_x / 255.)\n",
        "    cam_x = x + mask_x\n",
        "    cam_x = cam_x / cam_x.max()\n",
        "    return cam_x\n",
        "\n",
        "def generate_cam(cam_model, data_path, save_path, batch_size, device):\n",
        "    model = cam_model.model\n",
        "    imgs, labels, label_t, logits_, prods, masks = [], [], [], [], [], []\n",
        "    res = {}\n",
        "    data = np.load(data_path)\n",
        "    bx, by = data['img_x'], data['img_y']\n",
        "    for index, x in enumerate(bx):\n",
        "        x = torch.from_numpy(x.copy())\n",
        "        label = torch.tensor(by[index].copy())\n",
        "        x, label = torch.tensor(x[None], device=device, requires_grad=True), torch.tensor(by[index], device='cuda')\n",
        "        with torch.no_grad():\n",
        "            logits = model(imagenet_normalize(x))\n",
        "        logits_np = logits.cpu().numpy()[0]\n",
        "        logits_arg = np.argsort(logits_np).astype(np.int)\n",
        "        pred_label = int(logits_arg[-1])\n",
        "        if(pred_label != label):\n",
        "            continue\n",
        "        imgs.append(x.detach().cpu().numpy())\n",
        "        # res[\"pred_label\"] = pred_label\n",
        "        labels.append(pred_label)\n",
        "        label_t.append(data['img_yt'][index])\n",
        "\n",
        "        # res[\"logits_x\"] = logits_np\n",
        "        logits_.append(logits_np)\n",
        "        prod_x = cam_model(imagenet_normalize(x), label)[1]\n",
        "        mask_x = to_mask(prod_x.detach())\n",
        "        # res[\"prod_x\"] = prod_x.detach().cpu().numpy()[0]\n",
        "        prods.append(prod_x.detach().cpu().numpy()[0])\n",
        "        masks.append(mask_x[None].cpu().numpy())\n",
        "        # res[\"mask_x\"] = mask_x[None]\n",
        "    res['img_x'] = np.concatenate(imgs)\n",
        "    res[\"img_y\"] = labels\n",
        "    res[\"img_yt\"] = label_t\n",
        "    res[\"logits_x\"] = logits_\n",
        "    res[\"prod_x\"] = np.concatenate(prods)\n",
        "    res[\"mask_x\"] = np.concatenate(masks)\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "def main(data_path, save_path, batch_size, device):\n",
        "\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.train(False)\n",
        "    model.cuda()\n",
        "\n",
        "    cam_model = CAM(model)\n",
        "    res = generate_cam(cam_model, data_path, save_path, batch_size, device)\n",
        "    np.savez(save_path, **res)\n",
        "\n",
        "\n",
        "def generate_benign_cam(data_path, fName):\n",
        "#     data_path = 'data/fold_1.npz'\n",
        "    save_path = f'benign_cam_output_10000/{fName}'\n",
        "    batch_size=10\n",
        "    device = 'cuda'\n",
        "\n",
        "    if(not os.path.exists('benign_cam_output_10000/')):\n",
        "        os.mkdir('benign_cam_output_10000')\n",
        "\n",
        "    main(data_path, save_path, batch_size, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "62k8-0NOHYQn"
      },
      "outputs": [],
      "source": [
        "# files = os.listdir('10000_npz_images')\n",
        "# for f in files:\n",
        "#     generate_benign_cam(f'10000_npz_images/{f}', f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDVtW6taPhFW"
      },
      "source": [
        "Attack CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fmc1UsIq8crm"
      },
      "outputs": [],
      "source": [
        "class CustomCAM(object):\n",
        "\n",
        "    def __init__(self, model, output_keys=None):\n",
        "        self.model = model\n",
        "        self.model.cuda()\n",
        "        self.model.train(False)\n",
        "        if output_keys is not None:\n",
        "            self.output_keys = list(output_keys)\n",
        "        else:\n",
        "            self.output_keys = [\"l4\", \"gvp\", \"fc\"]\n",
        "\n",
        "    def forward(self, x, out_keys=None):\n",
        "        if out_keys is None:\n",
        "            out_keys = self.output_keys\n",
        "        res = self.model(x, out_keys)\n",
        "\n",
        "        rets = [res[key] for key in out_keys]\n",
        "        return rets\n",
        "\n",
        "    def __call__(self, x, y=None, out_keys=None):\n",
        "        if y is None:\n",
        "            with torch.no_grad():\n",
        "                _, _, logits = self.forward(x, out_keys=out_keys)\n",
        "                logits = logits.cpu().numpy()[0]\n",
        "            true_label = int(np.argmax(logits))\n",
        "            y = torch.tensor([true_label]).cuda()\n",
        "\n",
        "        l4, gvp, logits = self.forward(x)\n",
        "        wc = self.model.fc.weight[y].view(1, -1, 1, 1)\n",
        "        prod = (wc * l4).sum(1)\n",
        "\n",
        "        return logits, prod\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5F0EkNBD45bQ"
      },
      "outputs": [],
      "source": [
        "def cam_forward(model_tup, x):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    res = model(pre_fn(x), out_keys=[\"l4\", \"gvp\", \"fc\"])\n",
        "    return res['l4'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "def cam_fc_weight(model_tup):\n",
        "    model = model_tup[0]\n",
        "    return model.linear.weight\n",
        "\n",
        "\n",
        "def cam_resnet50():\n",
        "    model = resnet50(pretrained=True)\n",
        "    model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "    # ckpt_dict = torch.load(CIFAR10_RESNET50_CKPT_PATH, lambda storage, location: storage)['net']\n",
        "    # nn.DataParallel(model).load_state_dict(ckpt_dict)\n",
        "\n",
        "    return model_tup, (cam_forward, cam_fc_weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZcmKI3FeIB1"
      },
      "source": [
        "### AdvEdge+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "reXHL2EgVKdm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def generate_cams(model_tup, forward_tup, bx, by, device):\n",
        "    logits, cams = [], []\n",
        "    cam_model = CustomCAM(model_tup[0])\n",
        "    for index, img in enumerate(bx):\n",
        "        logit, prod_x = cam_model(model_tup[1](img[None]), by[index])\n",
        "    # print(logit.argmax().item())\n",
        "        logits.append(logit.squeeze())\n",
        "        cams.append(prod_x)\n",
        "    # mask_x = to_mask(prod_x.detach().cpu().numpy()[0])\n",
        "    # masks.append(mask_x)\n",
        "  # print(logits)\n",
        "    return torch.stack(logits, axis=0), torch.stack(cams, axis=0)\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(cam_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "    bx_adv = bx.clone().detach().requires_grad_()\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "    dobj = {}\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        logits = model(pre_fn(bx_adv))\n",
        "        loss = F.nll_loss(logits, by, reduction='sum')\n",
        "        loss_grad = autograd.grad([loss], [bx_adv])[0]\n",
        "\n",
        "        # first record message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                loss_adv_mu = np.asscalar(loss) / batch_size\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "            print('s1-step: %d, loss adv: %.2f, succeed: %d' % (i, loss_adv_mu, num_succeed))\n",
        "\n",
        "        # then update\n",
        "        with torch.no_grad():\n",
        "            loss_grad_sign = torch.where(weights > 0.1, loss_grad.sign(), torch.tensor(0.).to('cuda'))\n",
        "            bx_adv.data.add_(-s1_lr, loss_grad_sign)\n",
        "            diff = bx_adv - bx\n",
        "            diff.clamp_(-eps, eps)\n",
        "            bx_adv.data = diff + bx\n",
        "            bx_adv.data.clamp_(0, 1)\n",
        "\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "\n",
        "        conf_base = 0.95 + i / config['s2_iters'] * 0.04\n",
        "        conf = np.random.uniform(conf_base, 1, size=(batch_size, )).astype(np.float32)\n",
        "        conf_mat = ((1 - conf) / 9.).reshape((batch_size, 1)).repeat(1000, 1)\n",
        "        conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "\n",
        "        by_one = torch.tensor(conf_mat, device='cuda')\n",
        "        # adv_loss = (-by_one * F.log_softmax(logit)).sum()\n",
        "\n",
        "      # generate_cams\n",
        "        c_now += c_inc\n",
        "        logits, cam = generate_cams(model_tup, forward_tup, bx_adv, by, 'cuda')\n",
        "        # loss_adv = F.nll_loss(logits, by, reduction='sum')\n",
        "        loss_adv =  (-by_one * F.log_softmax(logits)).sum() #F.nll_loss(logits, by, reduction='sum')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = torch.sum((diff * diff).mean(1))\n",
        "        loss = torch.add(loss_adv, c_now, loss_cam)\n",
        "        loss_grad = autograd.grad([loss], [bx_adv])[0]\n",
        "\n",
        "        # print message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = np.asscalar(loss_cam) / batch_size\n",
        "                loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                loss_adv = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss cam: %.5f, succeed: %d' % (i, loss_adv, loss_cam, num_succeed))\n",
        "\n",
        "        # update\n",
        "        with torch.no_grad():\n",
        "            loss_grad_sign = loss_grad.sign()\n",
        "            bx_adv.data.add_(-s2_lr, loss_grad_sign)\n",
        "            diff = bx_adv - bx\n",
        "            diff.clamp_(-eps, eps)\n",
        "            bx_adv.data = diff + bx\n",
        "            bx_adv.data.clamp_(0, 1)\n",
        "        del loss_grad\n",
        "\n",
        "    logits, cam = generate_cams(model_tup, forward_tup, bx_adv, by, 'cuda')\n",
        "    cam_flatten = cam.view(batch_size, -1)\n",
        "    cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "    cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "    dobj['adv_x'] = bx_adv.detach().cpu().numpy()\n",
        "    dobj['adv_cam'] = cam_flatten.detach().cpu().numpy().reshape((batch_size, 1, 7, 7))\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['tcam'] = cam_benign\n",
        "    return dobj\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 1000\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "\n",
        "    # if(not os.path.exists('output/')):\n",
        "    #     os.mkdir('output')\n",
        "\n",
        "    attack(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_cam('fold_1.npz', 'output_2.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ1EwK9-_I0h",
        "outputId": "077f4efb-1e9a-4270-cd4b-238bb7d04c40"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:03<00:00, 31.9MB/s]\n",
            "<ipython-input-34-f306a398d18b>:51: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_adv_mu = np.asscalar(loss) / batch_size\n",
            "<ipython-input-34-f306a398d18b>:53: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1-step: 0, loss adv: -0.23, succeed: 0\n",
            "s1-step: 100, loss adv: -21.50, succeed: 5\n",
            "s1-step: 200, loss adv: -22.54, succeed: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f306a398d18b>:86: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  loss_adv =  (-by_one * F.log_softmax(logits)).sum() #F.nll_loss(logits, by, reduction='sum')\n",
            "<ipython-input-34-f306a398d18b>:99: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_cam_mu = np.asscalar(loss_cam) / batch_size\n",
            "<ipython-input-34-f306a398d18b>:100: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
            "<ipython-input-34-f306a398d18b>:101: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2-step: 0, loss adv: 61.83, loss cam: 0.11927, succeed: 5\n",
            "s2-step: 100, loss adv: 20.34, loss cam: 0.02100, succeed: 10\n",
            "s2-step: 200, loss adv: 18.04, loss cam: 0.01601, succeed: 10\n",
            "s2-step: 300, loss adv: 17.04, loss cam: 0.01253, succeed: 10\n",
            "s2-step: 400, loss adv: 18.21, loss cam: 0.01000, succeed: 10\n",
            "s2-step: 500, loss adv: 9.54, loss cam: 0.00866, succeed: 10\n",
            "s2-step: 600, loss adv: 15.90, loss cam: 0.00830, succeed: 10\n",
            "s2-step: 700, loss adv: 12.97, loss cam: 0.00891, succeed: 10\n",
            "s2-step: 800, loss adv: 11.47, loss cam: 0.00836, succeed: 10\n",
            "s2-step: 900, loss adv: 9.10, loss cam: 0.01052, succeed: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hC6TnYH2e7BQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# b_files = os.listdir('CAM/Resnet')\n",
        "\n",
        "# for index, f in enumerate(b_files):\n",
        "#     attack_cam(f'CAM/Resnet/{f}', f)\n",
        "#     print(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn3ZZM3T7Xgo"
      },
      "source": [
        "### AdvEdge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "_veamKzp7Xgo"
      },
      "outputs": [],
      "source": [
        "# class CustomCAM(object):\n",
        "\n",
        "#     def __init__(self, model, output_keys=None):\n",
        "#         self.model = model\n",
        "#         self.model.cuda()\n",
        "#         self.model.train(False)\n",
        "#         if output_keys is not None:\n",
        "#             self.output_keys = list(output_keys)\n",
        "#         else:\n",
        "#             self.output_keys = [\"l\", \"gvp\", \"fc\"]\n",
        "\n",
        "#     def forward(self, x, out_keys=None):\n",
        "#         if out_keys is None:\n",
        "#             out_keys = self.output_keys\n",
        "#         res = self.model(x, out_keys)\n",
        "\n",
        "#         rets = [res[key] for key in out_keys]\n",
        "#         return rets\n",
        "\n",
        "#     def __call__(self, x, y=None, out_keys=None):\n",
        "#         if y is None:\n",
        "#             with torch.no_grad():\n",
        "#                 _, _, logits = self.forward(x, out_keys=out_keys)\n",
        "#                 logits = logits.cpu().numpy()[0]\n",
        "#             true_label = int(np.argmax(logits))\n",
        "#             y = torch.tensor([true_label]).cuda()\n",
        "\n",
        "#         l4, gvp, logits = self.forward(x)\n",
        "#         wc = self.model.classifier.weight[y].view(1, -1, 1, 1)\n",
        "#         prod = (wc * l4).sum(1)\n",
        "\n",
        "#         return logits, prod\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9RmVyDt_7Xgo"
      },
      "outputs": [],
      "source": [
        "# def cam_forward(model_tup, x):\n",
        "#     model, pre_fn = model_tup[:2]\n",
        "#     res = model(pre_fn(x), out_keys=[\"l\", \"gvp\", \"fc\"])\n",
        "#     return res['l'], res['gvp'], res['fc']\n",
        "\n",
        "\n",
        "# def cam_fc_weight(model_tup):\n",
        "#     model = model_tup[0]\n",
        "#     return model.classifier.weight\n",
        "\n",
        "\n",
        "# def cam_densenet():\n",
        "#     model = densenet169(pretrained=True)\n",
        "#     model_tup = (model, imagenet_normalize, (224, 224))\n",
        "\n",
        "#     # ckpt_dict = torch.load(CIFAR10_RESNET50_CKPT_PATH, lambda storage, location: storage)['net']\n",
        "#     # nn.DataParallel(model).load_state_dict(ckpt_dict)\n",
        "\n",
        "#     return model_tup, (cam_forward, cam_fc_weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_4HrZvxFWKsL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def generate_cams(model_tup, forward_tup, bx, by, device):\n",
        "    logits, cams = [], []\n",
        "    cam_model = CustomCAM(model_tup[0])\n",
        "    for index, img in enumerate(bx):\n",
        "        logit, prod_x = cam_model(model_tup[1](img[None]), by[index])\n",
        "    # print(logit.argmax().item())\n",
        "        logits.append(logit.squeeze())\n",
        "        cams.append(prod_x)\n",
        "    # mask_x = to_mask(prod_x.detach().cpu().numpy()[0])\n",
        "    # masks.append(mask_x)\n",
        "  # print(logits)\n",
        "    return torch.stack(logits, axis=0), torch.stack(cams, axis=0)\n",
        "\n",
        "def attack_batch(config, model_tup, forward_tup, batch_tup, cam_benign):\n",
        "    model, pre_fn = model_tup[:2]\n",
        "    cuda = config['device'] == 'gpu'\n",
        "    bx_np, by_np = batch_tup\n",
        "    batch_size = len(bx_np)\n",
        "    bx, by = torch.tensor(bx_np), torch.tensor(by_np)\n",
        "    m0 = torch.tensor(cam_benign)\n",
        "    if cuda:\n",
        "        bx, by, m0 = bx.cuda(), by.cuda(), m0.cuda()\n",
        "    m0_flatten = m0.view(batch_size, -1)\n",
        "    bx_adv = bx.clone().detach().requires_grad_()\n",
        "\n",
        "    s1_lr = config['s1_lr']\n",
        "    s2_lr = config['s2_lr']\n",
        "    eps = config['epsilon']\n",
        "    dobj = {}\n",
        "\n",
        "    unpert_gray = bx.cpu().numpy().mean(axis = 1, keepdims=True)\n",
        "    # print(unpert_gray.shape)\n",
        "    edges = np.empty_like(unpert_gray)\n",
        "    # print(edges.shape)\n",
        "    for index, image in enumerate(unpert_gray):\n",
        "        edges[index] = filters.sobel(image.squeeze(0))\n",
        "    # print(edges.shape)\n",
        "    weights = torch.tensor(edges).to('cuda')\n",
        "\n",
        "\n",
        "    for i in range(config['s1_iters']):\n",
        "        logits = model(pre_fn(bx_adv))\n",
        "        loss = F.nll_loss(logits, by, reduction='sum')\n",
        "        loss_grad = autograd.grad([loss], [bx_adv])[0]\n",
        "\n",
        "        # first record message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                loss_adv_mu = np.asscalar(loss) / batch_size\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "            print('s1-step: %d, loss adv: %.2f, succeed: %d' % (i, loss_adv_mu, num_succeed))\n",
        "\n",
        "        # then update\n",
        "        with torch.no_grad():\n",
        "            loss_grad_sign = weights * loss_grad.sign()\n",
        "#             torch.where(weights > 0.1, loss_grad.sign(), torch.tensor(0.).to('cuda'))\n",
        "            bx_adv.data.add_(-s1_lr, loss_grad_sign)\n",
        "            diff = bx_adv - bx\n",
        "            diff.clamp_(-eps, eps)\n",
        "            bx_adv.data = diff + bx\n",
        "            bx_adv.data.clamp_(0, 1)\n",
        "\n",
        "    c_begin, c_final = config['c'], config['c'] * 2\n",
        "    c_inc = (c_final - c_begin) / config['s2_iters']\n",
        "    c_now = config['c']\n",
        "\n",
        "    label_indices = np.arange(0, batch_size, dtype=np.int64)\n",
        "\n",
        "    for i in range(config['s2_iters']):\n",
        "\n",
        "        conf_base = 0.95 + i / config['s2_iters'] * 0.04\n",
        "        conf = np.random.uniform(conf_base, 1, size=(batch_size, )).astype(np.float32)\n",
        "        conf_mat = ((1 - conf) / 9.).reshape((batch_size, 1)).repeat(1000, 1)\n",
        "        conf_mat[label_indices, by_np] = conf\n",
        "\n",
        "\n",
        "        by_one = torch.tensor(conf_mat, device='cuda')\n",
        "        # adv_loss = (-by_one * F.log_softmax(logit)).sum()\n",
        "\n",
        "      # generate_cams\n",
        "        c_now += c_inc\n",
        "        logits, cam = generate_cams(model_tup, forward_tup, bx_adv, by, 'cuda')\n",
        "        # loss_adv = F.nll_loss(logits, by, reduction='sum')\n",
        "        loss_adv =  (-by_one * F.log_softmax(logits)).sum() #F.nll_loss(logits, by, reduction='sum')\n",
        "        cam_flatten = cam.view(batch_size, -1)\n",
        "        cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "        cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "        diff = cam_flatten - m0_flatten\n",
        "        loss_cam = torch.sum((diff * diff).mean(1))\n",
        "        loss = torch.add(loss_adv, c_now, loss_cam)\n",
        "        loss_grad = autograd.grad([loss], [bx_adv])[0]\n",
        "\n",
        "        # print message\n",
        "        if i % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                pred = torch.argmax(logits, 1)\n",
        "                loss_cam_mu = np.asscalar(loss_cam) / batch_size\n",
        "                loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
        "                num_succeed = np.asscalar(torch.sum(by == pred))\n",
        "                loss_adv = loss_adv_mu\n",
        "                loss_cam = loss_cam_mu\n",
        "            print('s2-step: %d, loss adv: %.2f, loss cam: %.5f, succeed: %d' % (i, loss_adv, loss_cam, num_succeed))\n",
        "\n",
        "        # update\n",
        "        with torch.no_grad():\n",
        "            loss_grad_sign = loss_grad.sign()\n",
        "            bx_adv.data.add_(-s2_lr, loss_grad_sign)\n",
        "            diff = bx_adv - bx\n",
        "            diff.clamp_(-eps, eps)\n",
        "            bx_adv.data = diff + bx\n",
        "            bx_adv.data.clamp_(0, 1)\n",
        "        del loss_grad\n",
        "\n",
        "    logits, cam = generate_cams(model_tup, forward_tup, bx_adv, by, 'cuda')\n",
        "    cam_flatten = cam.view(batch_size, -1)\n",
        "    cam_flatten = cam_flatten - cam_flatten.min(1, True)[0]\n",
        "    cam_flatten = cam_flatten / cam_flatten.max(1, True)[0]\n",
        "    dobj['adv_x'] = bx_adv.detach().cpu().numpy()\n",
        "    dobj['pert'] = (bx_adv - bx).detach().cpu().numpy()\n",
        "    dobj['adv_cam'] = cam_flatten.detach().cpu().numpy().reshape((batch_size, 1, 7, 7))\n",
        "    dobj['adv_logits'] = logits.detach().cpu().numpy()\n",
        "    dobj['adv_succeed'] = (logits.argmax(1) == by).detach().cpu().numpy().astype(np.int64)\n",
        "    dobj['tcam'] = cam_benign\n",
        "    return dobj\n",
        "\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "def attack(config):\n",
        "    model_tup, forward_tup = cam_resnet50()\n",
        "    model_tup[0].train(False)\n",
        "    if config['device'] == 'gpu':\n",
        "        model_tup[0].cuda()\n",
        "    freeze_model(model_tup[0])\n",
        "\n",
        "    data_arx = np.load(config['data_path'])\n",
        "    img_x, img_yt = data_arx['img_x'], data_arx['img_yt']\n",
        "    cam_target = data_arx['mask_x']\n",
        "    # cam_benign = data_arx['att_bcams']\n",
        "\n",
        "    n, batch_size = len(img_x), config['batch_size']\n",
        "    num_batches = (n + batch_size - 1) // batch_size\n",
        "    save_dobjs = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        si = i * batch_size\n",
        "        ei = min(si + batch_size, n)\n",
        "        bx, byt, bm0 = img_x[si:ei], img_yt[si:ei], cam_target[si:ei]\n",
        "        dobj = attack_batch(config, model_tup, forward_tup, (bx, byt), bm0)\n",
        "        # dobj['bcam'] = cam_target[si:ei]\n",
        "        save_dobjs.append(dobj)\n",
        "\n",
        "    estimated_time = time.time() - start_time\n",
        "\n",
        "    keys = list(save_dobjs[0].keys())\n",
        "    save_dobj = {}\n",
        "    for key in keys:\n",
        "        save_dobj[key] = np.concatenate([i[key] for i in save_dobjs], axis=0)\n",
        "\n",
        "    save_dobj['time'] = estimated_time\n",
        "    save_dobj['img_y'] = data_arx['img_y']\n",
        "    np.savez(config['save_path'], **save_dobj)\n",
        "\n",
        "\n",
        "def attack_cam_1(data_path, fName):\n",
        "    config = {}\n",
        "    config['data_path'] = data_path\n",
        "    config['save_path'] = f'{fName}'\n",
        "    config['device'] = 'gpu'\n",
        "    config['batch_size'] = 10\n",
        "    config['epsilon'] = 0.031\n",
        "    config['s1_iters'] = 300\n",
        "    config['s1_lr'] = 1./255\n",
        "    config['s2_iters'] = 500\n",
        "    config['s2_lr'] = 1./255\n",
        "    config['c'] = 5.\n",
        "\n",
        "#     if(not os.path.exists('cam_resnet_our_1st_attack_output_10000/')):\n",
        "#         os.mkdir('cam_resnet_our_1st_attack_output_10000')\n",
        "\n",
        "    attack(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2MBdQcYCaCf",
        "outputId": "508c511b-3b94-40a3-b135-ec331aa00d90",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-0d5a90737298>:51: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_adv_mu = np.asscalar(loss) / batch_size\n",
            "<ipython-input-43-0d5a90737298>:53: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1-step: 0, loss adv: -0.23, succeed: 0\n",
            "s1-step: 100, loss adv: -52.83, succeed: 9\n",
            "s1-step: 200, loss adv: -76.24, succeed: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-0d5a90737298>:87: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  loss_adv =  (-by_one * F.log_softmax(logits)).sum() #F.nll_loss(logits, by, reduction='sum')\n",
            "<ipython-input-43-0d5a90737298>:100: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_cam_mu = np.asscalar(loss_cam) / batch_size\n",
            "<ipython-input-43-0d5a90737298>:101: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  loss_adv_mu = np.asscalar(loss_adv) / batch_size\n",
            "<ipython-input-43-0d5a90737298>:102: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "  num_succeed = np.asscalar(torch.sum(by == pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2-step: 0, loss adv: 181.79, loss cam: 0.09968, succeed: 9\n",
            "s2-step: 100, loss adv: 13.92, loss cam: 0.01616, succeed: 10\n"
          ]
        }
      ],
      "source": [
        "attack_cam_1('fold_1.npz', 'output_1.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWcdrJhR7Xgp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}